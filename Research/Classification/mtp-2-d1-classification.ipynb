{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10622934,"sourceType":"datasetVersion","datasetId":6577343},{"sourceId":10627200,"sourceType":"datasetVersion","datasetId":6579869},{"sourceId":10709822,"sourceType":"datasetVersion","datasetId":6637708}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:00.386851Z","iopub.execute_input":"2025-02-12T09:02:00.387214Z","iopub.status.idle":"2025-02-12T09:02:00.725250Z","shell.execute_reply.started":"2025-02-12T09:02:00.387188Z","shell.execute_reply":"2025-02-12T09:02:00.724355Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ogw3-loaded/data_frames_ogw3.pkl\n/kaggle/input/ogw3-train-test/test_dataset.npz\n/kaggle/input/ogw3-train-test/train_dataset.npz\n/kaggle/input/ogw3-augmented/X_damage_augmented.npy\n/kaggle/input/ogw3-augmented/X_freq_augmented.npy\n/kaggle/input/ogw3-augmented/X_signals_augmented.npy\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 1. Data Loading and Preprocessing ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T05:44:28.964911Z","iopub.execute_input":"2025-02-11T05:44:28.965491Z","iopub.status.idle":"2025-02-11T05:44:28.969912Z","shell.execute_reply.started":"2025-02-11T05:44:28.965449Z","shell.execute_reply":"2025-02-11T05:44:28.968930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:06:37.242029Z","iopub.execute_input":"2025-02-10T08:06:37.242374Z","iopub.status.idle":"2025-02-10T08:06:37.248948Z","shell.execute_reply.started":"2025-02-10T08:06:37.242345Z","shell.execute_reply":"2025-02-10T08:06:37.248048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.chdir(\"..\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:56:41.042296Z","iopub.execute_input":"2025-02-06T05:56:41.042651Z","iopub.status.idle":"2025-02-06T05:56:41.047280Z","shell.execute_reply.started":"2025-02-06T05:56:41.042625Z","shell.execute_reply":"2025-02-06T05:56:41.046185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:56:44.494816Z","iopub.execute_input":"2025-02-06T05:56:44.495167Z","iopub.status.idle":"2025-02-06T05:56:44.501488Z","shell.execute_reply.started":"2025-02-06T05:56:44.495141Z","shell.execute_reply":"2025-02-06T05:56:44.500513Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n%pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:56:45.114168Z","iopub.execute_input":"2025-02-06T05:56:45.114706Z","iopub.status.idle":"2025-02-06T05:56:45.123131Z","shell.execute_reply.started":"2025-02-06T05:56:45.114653Z","shell.execute_reply":"2025-02-06T05:56:45.121471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.chdir(\"input\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:56:46.059875Z","iopub.execute_input":"2025-02-06T05:56:46.060232Z","iopub.status.idle":"2025-02-06T05:56:46.064910Z","shell.execute_reply.started":"2025-02-06T05:56:46.060203Z","shell.execute_reply":"2025-02-06T05:56:46.063817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:56:47.023230Z","iopub.execute_input":"2025-02-06T05:56:47.023655Z","iopub.status.idle":"2025-02-06T05:57:20.806561Z","shell.execute_reply.started":"2025-02-06T05:56:47.023623Z","shell.execute_reply":"2025-02-06T05:57:20.805703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for k, v in obj.items():\n    print(k)\n    print(v.shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:20.808007Z","iopub.execute_input":"2025-02-06T05:57:20.808382Z","iopub.status.idle":"2025-02-06T05:57:20.813855Z","shell.execute_reply.started":"2025-02-06T05:57:20.808347Z","shell.execute_reply":"2025-02-06T05:57:20.812302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(obj)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:20.816048Z","iopub.execute_input":"2025-02-06T05:57:20.816306Z","iopub.status.idle":"2025-02-06T05:57:20.833412Z","shell.execute_reply.started":"2025-02-06T05:57:20.816283Z","shell.execute_reply":"2025-02-06T05:57:20.832246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline_data={}\ndamage_data={}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:20.834727Z","iopub.execute_input":"2025-02-06T05:57:20.835102Z","iopub.status.idle":"2025-02-06T05:57:20.848595Z","shell.execute_reply.started":"2025-02-06T05:57:20.835059Z","shell.execute_reply":"2025-02-06T05:57:20.847572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the columns to extract (0-based indexing)\n# columns_to_extract = [26, 34, 27, 35]  # Columns 27, 35, 28, 36 in 1-based indexing\ncolumns_to_extract = [26]  # Columns 27 in 1-based indexing\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:20.849771Z","iopub.execute_input":"2025-02-06T05:57:20.850132Z","iopub.status.idle":"2025-02-06T05:57:20.863965Z","shell.execute_reply.started":"2025-02-06T05:57:20.850092Z","shell.execute_reply":"2025-02-06T05:57:20.862548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Iterate through the items in the original dictionary\nfor k, v in obj.items():\n    if 'baseline' in k:\n        # Check if v is a Pandas DataFrame or NumPy array\n        if isinstance(v, pd.DataFrame):\n            filtered_data = v.iloc[:, columns_to_extract]  # Use .iloc for Pandas DataFrame\n        else:\n            filtered_data = v[:, columns_to_extract]  # Use NumPy slicing for arrays\n        \n        # Store the filtered data in the baseline dictionary\n        baseline_data[k] = filtered_data\n        \n        # Print dimensions for baseline data\n        #print(f\"Baseline key: {k}, Data shape: {filtered_data.shape}\")\n\n    elif 'D1' in k:  # Filter for D1\n        # Check if v is a Pandas DataFrame or NumPy array\n        if isinstance(v, pd.DataFrame):\n            filtered_data = v.iloc[:, columns_to_extract]  # Use .iloc for Pandas DataFrame\n        else:\n            filtered_data = v[:, columns_to_extract]  # Use NumPy slicing for arrays\n        \n        # Extract damage size from the key (number after 'S')\n        # Split the key by underscores and find the part starting with 'S'\n        damage_size_part = [part for part in k.split('_') if part.startswith('S')][0]\n        damage_size = int(damage_size_part[1:])  # Extract the number after 'S'\n        \n        # Store the filtered data and damage size in the damage dictionary\n        damage_data[k] = {\n            'data': filtered_data,\n            'damage_size': damage_size\n        }\n        \n        # Print dimensions for damage data\n        #print(f\"Damage key: {k}, Data shape: {filtered_data.shape}, Damage size: {damage_size}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:20.865265Z","iopub.execute_input":"2025-02-06T05:57:20.865786Z","iopub.status.idle":"2025-02-06T05:57:21.238995Z","shell.execute_reply.started":"2025-02-06T05:57:20.865731Z","shell.execute_reply":"2025-02-06T05:57:21.238088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(baseline_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:21.239942Z","iopub.execute_input":"2025-02-06T05:57:21.240282Z","iopub.status.idle":"2025-02-06T05:57:21.246279Z","shell.execute_reply.started":"2025-02-06T05:57:21.240237Z","shell.execute_reply":"2025-02-06T05:57:21.245421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(damage_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:21.248740Z","iopub.execute_input":"2025-02-06T05:57:21.249131Z","iopub.status.idle":"2025-02-06T05:57:21.266969Z","shell.execute_reply.started":"2025-02-06T05:57:21.249104Z","shell.execute_reply":"2025-02-06T05:57:21.265965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize lists to store all samples and labels\nX_all = []\ny_all = []\n\n# Add baseline samples\nfor k, v in baseline_data.items():\n    X_all.append(v)  # Shape: (4369, 1)\n    y_all.append(0)  # Label for baseline\n\n# Add damage samples\nfor k, v in damage_data.items():\n    X_all.append(v['data'])  # Shape: (4369, 1)\n    y_all.append(v['damage_size'])  # Label for damage\n\n# Convert lists to NumPy arrays\nX_all = np.array(X_all)  # Shape: (num_samples, 4369, 4)\ny_all = np.array(y_all)  # Shape: (num_samples,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:21.268516Z","iopub.execute_input":"2025-02-06T05:57:21.268883Z","iopub.status.idle":"2025-02-06T05:57:21.329750Z","shell.execute_reply.started":"2025-02-06T05:57:21.268855Z","shell.execute_reply":"2025-02-06T05:57:21.328621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=0.2, random_state=42\n)\n\n# Print shapes for verification\nprint(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples * 0.8, 4369, 4)\nprint(f\"Training labels shape: {y_train.shape}\")  # Should be (num_samples * 0.8,)\nprint(f\"Test data shape: {X_test.shape}\")  # Should be (num_samples * 0.2, 4369, 4)\nprint(f\"Test labels shape: {y_test.shape}\")  # Should be (num_samples * 0.2,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:21.331029Z","iopub.execute_input":"2025-02-06T05:57:21.331301Z","iopub.status.idle":"2025-02-06T05:57:21.953706Z","shell.execute_reply.started":"2025-02-06T05:57:21.331279Z","shell.execute_reply":"2025-02-06T05:57:21.952503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_label_distribution(y, set_name):\n    \"\"\"Print the distribution of labels in a dataset.\"\"\"\n    print(f\"\\n{set_name} label distribution:\")\n    print(f\"- Baseline samples (0): {np.sum(y == 0)}\")\n    for damage_size in range(1, 14):\n        print(f\"- Damage size {damage_size}: {np.sum(y == damage_size)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:21.954492Z","iopub.execute_input":"2025-02-06T05:57:21.954953Z","iopub.status.idle":"2025-02-06T05:57:21.960341Z","shell.execute_reply.started":"2025-02-06T05:57:21.954926Z","shell.execute_reply":"2025-02-06T05:57:21.959005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print label distribution for training and test sets\nprint_label_distribution(y_train, \"Training set\")\nprint_label_distribution(y_test, \"Test set\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:21.961277Z","iopub.execute_input":"2025-02-06T05:57:21.961605Z","iopub.status.idle":"2025-02-06T05:57:21.986143Z","shell.execute_reply.started":"2025-02-06T05:57:21.961580Z","shell.execute_reply":"2025-02-06T05:57:21.985150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:41.738750Z","iopub.execute_input":"2025-02-06T05:57:41.739118Z","iopub.status.idle":"2025-02-06T05:57:41.745472Z","shell.execute_reply.started":"2025-02-06T05:57:41.739086Z","shell.execute_reply":"2025-02-06T05:57:41.744264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.chdir(\"..\")\nos.chdir(\"working\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:42.825519Z","iopub.execute_input":"2025-02-06T05:57:42.825860Z","iopub.status.idle":"2025-02-06T05:57:42.830261Z","shell.execute_reply.started":"2025-02-06T05:57:42.825832Z","shell.execute_reply":"2025-02-06T05:57:42.828859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.savez(\"train_dataset_D1.npz\", X=X_train, y=y_train)\nnp.savez(\"test_dataset_D1.npz\", X=X_test, y=y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:57:44.415380Z","iopub.execute_input":"2025-02-06T05:57:44.415723Z","iopub.status.idle":"2025-02-06T05:57:44.522828Z","shell.execute_reply.started":"2025-02-06T05:57:44.415694Z","shell.execute_reply":"2025-02-06T05:57:44.521670Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1.5) loading augmented data","metadata":{}},{"cell_type":"code","source":"%pwd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:08.873904Z","iopub.execute_input":"2025-02-12T09:02:08.874331Z","iopub.status.idle":"2025-02-12T09:02:08.880165Z","shell.execute_reply.started":"2025-02-12T09:02:08.874307Z","shell.execute_reply":"2025-02-12T09:02:08.879421Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:12.770669Z","iopub.execute_input":"2025-02-12T09:02:12.770950Z","iopub.status.idle":"2025-02-12T09:02:12.774541Z","shell.execute_reply.started":"2025-02-12T09:02:12.770930Z","shell.execute_reply":"2025-02-12T09:02:12.773698Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"os.chdir(\"..\")\nos.chdir(\"input\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:13.761518Z","iopub.execute_input":"2025-02-12T09:02:13.761828Z","iopub.status.idle":"2025-02-12T09:02:13.765440Z","shell.execute_reply.started":"2025-02-12T09:02:13.761802Z","shell.execute_reply":"2025-02-12T09:02:13.764608Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"X_signals_augmented = np.load('ogw3-augmented/X_signals_augmented.npy')\nX_damage_augmented = np.load('ogw3-augmented/X_damage_augmented.npy')\nX_freq_augmented = np.load('ogw3-augmented/X_freq_augmented.npy')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:16.196736Z","iopub.execute_input":"2025-02-12T09:02:16.197038Z","iopub.status.idle":"2025-02-12T09:02:17.643930Z","shell.execute_reply.started":"2025-02-12T09:02:16.197015Z","shell.execute_reply":"2025-02-12T09:02:17.643020Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(f\"X_signals shape:{X_signals_augmented.shape}\")\nprint(f\"X_signals shape:{X_damage_augmented.shape}\")\nprint(f\"X_signals shape:{X_freq_augmented.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:18.918736Z","iopub.execute_input":"2025-02-12T09:02:18.919014Z","iopub.status.idle":"2025-02-12T09:02:18.923691Z","shell.execute_reply.started":"2025-02-12T09:02:18.918995Z","shell.execute_reply":"2025-02-12T09:02:18.922930Z"}},"outputs":[{"name":"stdout","text":"X_signals shape:(2040, 4369, 1)\nX_signals shape:(2040, 14)\nX_signals shape:(2040, 12)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\n\ndef summarize_data(X, name):\n    print(f\"Summary for {name}:\")\n    print(\"Mean:\", np.mean(X, axis=0))\n    print(\"Variance:\", np.var(X, axis=0))\n    print(\"Min:\", np.min(X, axis=0))\n    print(\"Max:\", np.max(X, axis=0))\n    print(\"-\" * 50)\n\nsummarize_data(X_signals_augmented, \"X_signals_augmented\")\nsummarize_data(X_freq_augmented, \"X_freq_augmented\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:20.359431Z","iopub.execute_input":"2025-02-12T09:02:20.359703Z","iopub.status.idle":"2025-02-12T09:02:20.460146Z","shell.execute_reply.started":"2025-02-12T09:02:20.359683Z","shell.execute_reply":"2025-02-12T09:02:20.459423Z"}},"outputs":[{"name":"stdout","text":"Summary for X_signals_augmented:\nMean: [[-0.00808563]\n [-0.03676917]\n [ 0.00793156]\n ...\n [ 0.43494834]\n [ 0.47826858]\n [ 0.47794448]]\nVariance: [[0.04756828]\n [0.05728288]\n [0.05182533]\n ...\n [0.11266843]\n [0.11778735]\n [0.1192308 ]]\nMin: [[-1.]\n [-1.]\n [-1.]\n ...\n [-1.]\n [-1.]\n [-1.]]\nMax: [[1.]\n [1.]\n [1.]\n ...\n [1.]\n [1.]\n [1.]]\n--------------------------------------------------\nSummary for X_freq_augmented:\nMean: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\nVariance: [0.07638889 0.07638889 0.07638889 0.07638889 0.07638889 0.07638889\n 0.07638889 0.07638889 0.07638889 0.07638889 0.07638889 0.07638889]\nMin: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\nMax: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\ndamage_counts = pd.Series(X_damage_augmented.flatten()).value_counts()\nprint(\"Damage Condition Counts:\\n\", damage_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:22.846735Z","iopub.execute_input":"2025-02-12T09:02:22.847036Z","iopub.status.idle":"2025-02-12T09:02:22.865023Z","shell.execute_reply.started":"2025-02-12T09:02:22.847011Z","shell.execute_reply":"2025-02-12T09:02:22.863995Z"}},"outputs":[{"name":"stdout","text":"Damage Condition Counts:\n 0.0    26520\n1.0     2040\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# 2. Execution and model Training\nThis is where the actual execution starts","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport matplotlib.pyplot as plt\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:23.440458Z","iopub.execute_input":"2025-02-12T09:02:23.440785Z","iopub.status.idle":"2025-02-12T09:02:23.444515Z","shell.execute_reply.started":"2025-02-12T09:02:23.440758Z","shell.execute_reply":"2025-02-12T09:02:23.443670Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"os.chdir(\"..\")\nos.chdir(\"working\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:25.540784Z","iopub.execute_input":"2025-02-12T09:02:25.541098Z","iopub.status.idle":"2025-02-12T09:02:25.545018Z","shell.execute_reply.started":"2025-02-12T09:02:25.541072Z","shell.execute_reply":"2025-02-12T09:02:25.544109Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"os.chdir(\"..\")\n%pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:26.168686Z","iopub.execute_input":"2025-02-12T09:02:26.168970Z","iopub.status.idle":"2025-02-12T09:02:26.174284Z","shell.execute_reply.started":"2025-02-12T09:02:26.168948Z","shell.execute_reply":"2025-02-12T09:02:26.173444Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'/kaggle'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"os.chdir('input/ogw3-train-test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:26.846656Z","iopub.execute_input":"2025-02-12T09:02:26.846972Z","iopub.status.idle":"2025-02-12T09:02:26.850798Z","shell.execute_reply.started":"2025-02-12T09:02:26.846946Z","shell.execute_reply":"2025-02-12T09:02:26.849729Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# ----------------------------------------------------------------------\n# Step 1: Convert one-hot encoded damage labels to scalar values.\n# ----------------------------------------------------------------------\n# Each sample in X_damage_augmented is a one-hot vector. We convert it to the\n# corresponding class index (i.e., 0 for undamaged, 1-13 for damage levels).\ny_augmented = np.argmax(X_damage_augmented, axis=1).astype(np.float32)\n# y_augmented now has shape (num_samples,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:32.939771Z","iopub.execute_input":"2025-02-12T09:02:32.940050Z","iopub.status.idle":"2025-02-12T09:02:33.476659Z","shell.execute_reply.started":"2025-02-12T09:02:32.940030Z","shell.execute_reply":"2025-02-12T09:02:33.475949Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"y_augmented.min()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:33.539296Z","iopub.execute_input":"2025-02-12T09:02:33.539640Z","iopub.status.idle":"2025-02-12T09:02:33.544589Z","shell.execute_reply.started":"2025-02-12T09:02:33.539611Z","shell.execute_reply":"2025-02-12T09:02:33.543736Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# ----------------------------------------------------------------------\n# Step 2: Define the features.\n# ----------------------------------------------------------------------\n# For this regression task, we use the guided wave signals as the features.\n# (If you wish to include frequency information as additional features, you might\n# concatenate or process X_freq_augmented separately; here we assume only the signal is used.)\nX_augmented = X_signals_augmented  # shape: (num_samples, 4369, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:34.319786Z","iopub.execute_input":"2025-02-12T09:02:34.320218Z","iopub.status.idle":"2025-02-12T09:02:34.323897Z","shell.execute_reply.started":"2025-02-12T09:02:34.320182Z","shell.execute_reply":"2025-02-12T09:02:34.323142Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# ----------------------------------------------------------------------\n# Step 3: Split the data into training and test sets.\n# ----------------------------------------------------------------------\n# Here we use 80% of the data for training and 20% for testing.\nX_train, X_test, y_train, y_test = train_test_split(\n    X_augmented, y_augmented, test_size=0.1, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:35.951523Z","iopub.execute_input":"2025-02-12T09:02:35.951814Z","iopub.status.idle":"2025-02-12T09:02:35.983209Z","shell.execute_reply.started":"2025-02-12T09:02:35.951793Z","shell.execute_reply":"2025-02-12T09:02:35.982538Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\n\n\n# ----------------------------------------------------------------------\n# Step 4: Verify the shapes of the datasets.\n# ----------------------------------------------------------------------\nprint(f\"Training data shape: {X_train.shape}\")  # Expected: (num_train_samples, 4369, 1)\nprint(f\"Training labels shape: {y_train.shape}\")  # Expected: (num_train_samples,)\nprint(f\"Test data shape: {X_test.shape}\")         # Expected: (num_test_samples, 4369, 1)\nprint(f\"Test labels shape: {y_test.shape}\")         # Expected: (num_test_samples,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:43.000314Z","iopub.execute_input":"2025-02-12T09:02:43.000633Z","iopub.status.idle":"2025-02-12T09:02:43.006566Z","shell.execute_reply.started":"2025-02-12T09:02:43.000610Z","shell.execute_reply":"2025-02-12T09:02:43.005626Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (1836, 4369, 1)\nTraining labels shape: (1836,)\nTest data shape: (204, 4369, 1)\nTest labels shape: (204,)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"\n# # Load training dataset\n# train_data = np.load(\"train_dataset_D1.npz\")\n# X_train = train_data[\"X\"]  # Load features\n# y_train = train_data[\"y\"]  # Load labels\n\n# # Load test dataset\n# test_data = np.load(\"test_dataset_D1.npz\")\n# X_test = test_data[\"X\"]  # Load features\n# y_test = test_data[\"y\"]  # Load labels\n\n# # Verify shapes\n# print(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples, 4369, 4)\n# print(f\"Training labels shape: {y_train.shape}\")  # Should be (num_samples,)\n# print(f\"Test data shape: {X_test.shape}\")  # Should be (num_samples, 4369, 4)\n# print(f\"Test labels shape: {y_test.shape}\")  # Should be (num_samples,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:44.839216Z","iopub.execute_input":"2025-02-12T09:02:44.839497Z","iopub.status.idle":"2025-02-12T09:02:44.843037Z","shell.execute_reply.started":"2025-02-12T09:02:44.839476Z","shell.execute_reply":"2025-02-12T09:02:44.841981Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def print_label_distribution(y, set_name):\n    \"\"\"Print the distribution of labels in a dataset.\"\"\"\n    print(f\"\\n{set_name} label distribution:\")\n    print(f\"- Baseline samples (0): {np.sum(y == 0)}\")\n    for damage_size in range(1, 14):\n        print(f\"- Damage size {damage_size}: {np.sum(y == damage_size)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:46.140402Z","iopub.execute_input":"2025-02-12T09:02:46.140682Z","iopub.status.idle":"2025-02-12T09:02:46.145387Z","shell.execute_reply.started":"2025-02-12T09:02:46.140662Z","shell.execute_reply":"2025-02-12T09:02:46.144411Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Print label distribution for training and test sets\nprint_label_distribution(y_train, \"Training set\")\nprint_label_distribution(y_test, \"Test set\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:46.434658Z","iopub.execute_input":"2025-02-12T09:02:46.434935Z","iopub.status.idle":"2025-02-12T09:02:46.444677Z","shell.execute_reply.started":"2025-02-12T09:02:46.434914Z","shell.execute_reply":"2025-02-12T09:02:46.443899Z"}},"outputs":[{"name":"stdout","text":"\nTraining set label distribution:\n- Baseline samples (0): 433\n- Damage size 1: 107\n- Damage size 2: 107\n- Damage size 3: 105\n- Damage size 4: 106\n- Damage size 5: 105\n- Damage size 6: 107\n- Damage size 7: 115\n- Damage size 8: 109\n- Damage size 9: 107\n- Damage size 10: 111\n- Damage size 11: 109\n- Damage size 12: 111\n- Damage size 13: 104\n\nTest set label distribution:\n- Baseline samples (0): 47\n- Damage size 1: 13\n- Damage size 2: 13\n- Damage size 3: 15\n- Damage size 4: 14\n- Damage size 5: 15\n- Damage size 6: 13\n- Damage size 7: 5\n- Damage size 8: 11\n- Damage size 9: 13\n- Damage size 10: 9\n- Damage size 11: 11\n- Damage size 12: 9\n- Damage size 13: 16\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# import numpy as np\n\n# def min_max_scale(data):\n#     \"\"\"Normalize each feature (column) to [0, 1].\"\"\"\n#     min_vals = np.min(data, keepdims=True)  # Min along time steps\n#     max_vals = np.max(data, keepdims=True)  # Max along time steps\n#     return (data - min_vals) / (max_vals - min_vals + 1e-8)  # Avoid division by zero\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:49.440672Z","iopub.execute_input":"2025-02-12T09:02:49.440957Z","iopub.status.idle":"2025-02-12T09:02:49.444205Z","shell.execute_reply.started":"2025-02-12T09:02:49.440936Z","shell.execute_reply":"2025-02-12T09:02:49.443416Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# X_train_scaled = np.array([min_max_scale(sample) for sample in X_train])\n# X_test_scaled = np.array([min_max_scale(sample) for sample in X_test])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:49.663514Z","iopub.execute_input":"2025-02-12T09:02:49.663782Z","iopub.status.idle":"2025-02-12T09:02:49.666975Z","shell.execute_reply.started":"2025-02-12T09:02:49.663763Z","shell.execute_reply":"2025-02-12T09:02:49.666089Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# X_train=X_train_scaled\n# X_test=X_test_scaled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:49.724899Z","iopub.execute_input":"2025-02-12T09:02:49.725156Z","iopub.status.idle":"2025-02-12T09:02:49.728310Z","shell.execute_reply.started":"2025-02-12T09:02:49.725118Z","shell.execute_reply":"2025-02-12T09:02:49.727477Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Convert input data to float32\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:53.407904Z","iopub.execute_input":"2025-02-12T09:02:53.408251Z","iopub.status.idle":"2025-02-12T09:02:53.429335Z","shell.execute_reply.started":"2025-02-12T09:02:53.408223Z","shell.execute_reply":"2025-02-12T09:02:53.428586Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"y_train = y_train.astype('int32')\ny_test = y_test.astype('int32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:04:16.867273Z","iopub.execute_input":"2025-02-12T09:04:16.867559Z","iopub.status.idle":"2025-02-12T09:04:16.871380Z","shell.execute_reply.started":"2025-02-12T09:04:16.867539Z","shell.execute_reply":"2025-02-12T09:04:16.870505Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"print(\"Min values after scaling:\", np.min(X_train, axis=(1,2)))\nprint(\"Max values after scaling:\", np.max(X_train, axis=(1,2)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:55.300056Z","iopub.execute_input":"2025-02-12T09:02:55.300522Z","iopub.status.idle":"2025-02-12T09:02:55.321459Z","shell.execute_reply.started":"2025-02-12T09:02:55.300490Z","shell.execute_reply":"2025-02-12T09:02:55.320790Z"}},"outputs":[{"name":"stdout","text":"Min values after scaling: [-1.040155  -0.9812768 -1.        ... -1.        -0.9722817 -0.9399686]\nMax values after scaling: [1.0318567  0.94322634 1.         ... 1.         0.9312466  1.0010613 ]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"X_train dtype:\", X_train.dtype)  # Should print float32\nprint(\"y_train dtype:\", y_train.dtype)  # Should print float32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:57.553754Z","iopub.execute_input":"2025-02-12T09:02:57.554055Z","iopub.status.idle":"2025-02-12T09:02:57.559036Z","shell.execute_reply.started":"2025-02-12T09:02:57.554033Z","shell.execute_reply":"2025-02-12T09:02:57.558161Z"}},"outputs":[{"name":"stdout","text":"X_train dtype: float32\ny_train dtype: float32\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import numpy as np\n\n# Compute the minimum and maximum values from the training targets.\ny_min = np.min(y_train)\ny_max = np.max(y_train)\n\n# Normalize the training and test targets.\ny_train_norm = (y_train - y_min) / (y_max - y_min)\ny_test_norm = (y_test - y_min) / (y_max - y_min)\n\n\nprint(\"Before Normalizing training targets (first 5):\", y_train[:5])\nprint(\"Before Normalizing test targets (first 5):\", y_test[:5])\n\nprint(\"Normalized training targets (first 5):\", y_train_norm[:5])\nprint(\"Normalized test targets (first 5):\", y_test_norm[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:02:59.485839Z","iopub.execute_input":"2025-02-12T09:02:59.486183Z","iopub.status.idle":"2025-02-12T09:02:59.493629Z","shell.execute_reply.started":"2025-02-12T09:02:59.486119Z","shell.execute_reply":"2025-02-12T09:02:59.492766Z"}},"outputs":[{"name":"stdout","text":"Before Normalizing training targets (first 5): [ 5.  3. 13.  1. 10.]\nBefore Normalizing test targets (first 5): [7. 0. 6. 1. 8.]\nNormalized training targets (first 5): [0.3846154  0.23076923 1.         0.07692308 0.7692308 ]\nNormalized test targets (first 5): [0.53846157 0.         0.46153846 0.07692308 0.61538464]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# 3. Model Architecture","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:01.564351Z","iopub.execute_input":"2025-02-12T09:03:01.564649Z","iopub.status.idle":"2025-02-12T09:03:13.422812Z","shell.execute_reply.started":"2025-02-12T09:03:01.564628Z","shell.execute_reply":"2025-02-12T09:03:13.422064Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"tf.keras.backend.set_floatx('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:13.423930Z","iopub.execute_input":"2025-02-12T09:03:13.424447Z","iopub.status.idle":"2025-02-12T09:03:13.428176Z","shell.execute_reply.started":"2025-02-12T09:03:13.424423Z","shell.execute_reply":"2025-02-12T09:03:13.427220Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:13.429901Z","iopub.execute_input":"2025-02-12T09:03:13.430220Z","iopub.status.idle":"2025-02-12T09:03:13.457094Z","shell.execute_reply.started":"2025-02-12T09:03:13.430190Z","shell.execute_reply":"2025-02-12T09:03:13.456452Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Multi-GPU setup\nstrategy = tf.distribute.MirroredStrategy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:13.458330Z","iopub.execute_input":"2025-02-12T09:03:13.458695Z","iopub.status.idle":"2025-02-12T09:03:14.421410Z","shell.execute_reply.started":"2025-02-12T09:03:13.458665Z","shell.execute_reply":"2025-02-12T09:03:14.420517Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Transformer Encoder block definition \ndef transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n    # Attention and Normalization\n    x = layers.MultiHeadAttention(\n        key_dim=head_size, num_heads=num_heads, dropout=dropout\n    )(inputs, inputs)\n    x = layers.Dropout(dropout)(x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    res = x + inputs\n\n    # Feed Forward part\n    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n    x = layers.Dropout(dropout)(x)\n    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    return x + res\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:14.422268Z","iopub.execute_input":"2025-02-12T09:03:14.422519Z","iopub.status.idle":"2025-02-12T09:03:14.428275Z","shell.execute_reply.started":"2025-02-12T09:03:14.422488Z","shell.execute_reply":"2025-02-12T09:03:14.427441Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Model building function adapted for multi-class classification\ndef build_model(\n    input_shape,\n    head_size,\n    num_heads,\n    ff_dim,\n    num_transformer_blocks,\n    mlp_units,\n    dropout=0,\n    mlp_dropout=0,\n    num_classes=14  # Added parameter for number of classes\n):\n    inputs = keras.Input(shape=input_shape)\n    # Reshape the input to 3D (batch_size, 874, 1)\n    x = layers.Reshape((input_shape[0], 1))(inputs)\n    \n    # Apply multiple Transformer Encoder blocks\n    for _ in range(num_transformer_blocks):\n        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n\n    # Flatten the tensor for the MLP part\n    x = layers.Flatten()(x)\n    \n    # MLP layers\n    for dim in mlp_units:\n        x = layers.Dense(dim, activation=\"relu\")(x)\n        x = layers.Dropout(mlp_dropout)(x)\n    \n    # Output layer for multi-class classification\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n    return keras.Model(inputs, outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:17.341892Z","iopub.execute_input":"2025-02-12T09:03:17.342226Z","iopub.status.idle":"2025-02-12T09:03:17.347609Z","shell.execute_reply.started":"2025-02-12T09:03:17.342197Z","shell.execute_reply":"2025-02-12T09:03:17.346665Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Multi-GPU strategy scope\nwith strategy.scope():\n    input_shape = (874,)  # Adjusted input shape\n\n    model = build_model(\n        input_shape,\n        head_size=512,\n        num_heads=8,\n        ff_dim=128,\n        num_transformer_blocks=4,\n        mlp_units=[256],\n        mlp_dropout=0.4,\n        dropout=0.3,\n        num_classes=14  # Specify 14 classes (0-13 damage levels)\n    )\n\n    # Compilation with multi-class classification loss\n    # Use \"sparse_categorical_crossentropy\" if your labels are integer-encoded (0 to 13)\n    model.compile(\n        loss=\"sparse_categorical_crossentropy\",\n        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n        metrics=[\"accuracy\"],\n    )\n\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:20.113028Z","iopub.execute_input":"2025-02-12T09:03:20.113396Z","iopub.status.idle":"2025-02-12T09:03:21.893626Z","shell.execute_reply.started":"2025-02-12T09:03:20.113369Z","shell.execute_reply":"2025-02-12T09:03:21.892936Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m28,673\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m129\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m28,673\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m129\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m28,673\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m129\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m28,673\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n│                           │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m129\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_7… │\n│                           │                        │                │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m874\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m224,000\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │          \u001b[38;5;34m3,598\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">28,673</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">28,673</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">28,673</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">28,673</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n│                           │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7… │\n│                           │                        │                │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">874</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224,000</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,598</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m343,846\u001b[0m (1.31 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">343,846</span> (1.31 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m343,846\u001b[0m (1.31 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">343,846</span> (1.31 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:26.722095Z","iopub.execute_input":"2025-02-12T09:03:26.722438Z","iopub.status.idle":"2025-02-12T09:03:26.727624Z","shell.execute_reply.started":"2025-02-12T09:03:26.722412Z","shell.execute_reply":"2025-02-12T09:03:26.726903Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(1836, 4369, 1)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"y_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:03:27.803538Z","iopub.execute_input":"2025-02-12T09:03:27.803822Z","iopub.status.idle":"2025-02-12T09:03:27.808852Z","shell.execute_reply.started":"2025-02-12T09:03:27.803800Z","shell.execute_reply":"2025-02-12T09:03:27.807935Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(1836,)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"y_train,y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:04:29.170804Z","iopub.execute_input":"2025-02-12T09:04:29.171115Z","iopub.status.idle":"2025-02-12T09:04:29.177374Z","shell.execute_reply.started":"2025-02-12T09:04:29.171091Z","shell.execute_reply":"2025-02-12T09:04:29.176245Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(array([ 5,  3, 13, ...,  0,  4,  6], dtype=int32),\n array([ 7,  0,  6,  1,  8,  4,  0,  4,  0,  1,  4,  9,  9, 12,  3, 13,  5,\n         5,  2,  9,  0,  0, 12,  8,  3,  0,  0,  4,  0,  1,  3,  0,  7,  5,\n         5,  9, 10, 10,  4,  0,  0,  3,  5, 10, 13, 12,  7,  2,  0,  0,  0,\n         0,  0, 11,  6,  6, 12,  0,  4,  0,  0,  3,  4,  6,  9,  0,  6,  8,\n         5,  0,  6, 12,  0,  5,  3, 13,  1,  0,  9, 11,  6,  6,  9,  0,  8,\n         4,  5,  0, 13, 12,  1,  2,  3,  0,  3,  0,  4,  8,  8,  5,  5,  3,\n        12, 13, 13,  5,  0,  6,  0, 11, 11,  1,  0,  1,  8,  0,  0,  0, 13,\n         0,  2, 12,  0, 11,  6, 13,  5, 10, 10,  4,  2, 13,  9,  2,  2,  4,\n         0,  1,  9,  3,  0,  7, 11,  1,  0,  5,  8,  1,  9, 10,  5, 12,  1,\n         0,  2,  3, 13,  5,  2,  0,  2,  4,  4,  0, 11,  0, 10, 13, 10,  4,\n         3, 10,  9, 13,  2,  0,  8,  6,  3,  9,  6,  0,  6,  9, 11, 11,  3,\n        13,  8,  0, 11, 13,  1,  8,  7,  2, 13, 13,  0,  3,  1, 11,  2,  0],\n       dtype=int32))"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# Assume X_train has the shape (num_samples, 4369, 1)\nnum_samples, original_length, channels = X_train.shape\n\n# Calculate padding length so that the length becomes divisible by 5.\npad_len = 1\n\n# Pad along the sequence axis (axis=1) with -np.inf so that the max operation is not affected.\nX_train_padded = np.pad(\n    X_train,\n    pad_width=((0, 0), (0, pad_len), (0, 0)),\n    mode='constant',\n    constant_values=-np.inf\n)\n\n# Now X_train_padded has the shape (num_samples, 4370, 1).\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:04:36.255791Z","iopub.execute_input":"2025-02-12T09:04:36.256097Z","iopub.status.idle":"2025-02-12T09:04:36.272996Z","shell.execute_reply.started":"2025-02-12T09:04:36.256075Z","shell.execute_reply":"2025-02-12T09:04:36.272209Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"X_train_padded.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:04:38.129638Z","iopub.execute_input":"2025-02-12T09:04:38.129927Z","iopub.status.idle":"2025-02-12T09:04:38.135331Z","shell.execute_reply.started":"2025-02-12T09:04:38.129906Z","shell.execute_reply":"2025-02-12T09:04:38.134434Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"(1836, 4370, 1)"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"\n# Reshape to group every 5 consecutive elements:\n# New shape will be (num_samples, 874, 5, 1)\ngrouped_length = X_train_padded.shape[1] // 5  # Should be 874\nX_train_grouped = X_train_padded.reshape(num_samples, grouped_length, 5, channels)\n\n# Take the max over the 5 elements for each group (axis=2)\n# Resulting shape is (num_samples, 874, 1)\nX_train_max = np.max(X_train_grouped, axis=2)\n\n# Optionally, if your model expects inputs of shape (num_samples, 874),\n# reshape the array from (num_samples, 874, 1) to (num_samples, 874)\nX_train_final = X_train_max.reshape(num_samples, grouped_length)\n\n# Check the resulting shape\nprint(\"Shape after max-pooling and reshaping:\", X_train_final.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:04:40.739902Z","iopub.execute_input":"2025-02-12T09:04:40.740204Z","iopub.status.idle":"2025-02-12T09:04:40.935235Z","shell.execute_reply.started":"2025-02-12T09:04:40.740182Z","shell.execute_reply":"2025-02-12T09:04:40.934460Z"}},"outputs":[{"name":"stdout","text":"Shape after max-pooling and reshaping: (1836, 874)\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# Assume X_train has the shape (num_samples, 4369, 1)\nnum_samples, original_length, channels = X_test.shape\n\n# Calculate padding length so that the length becomes divisible by 5.\npad_len = 1\n\n# Pad along the sequence axis (axis=1) with -np.inf so that the max operation is not affected.\nX_test_padded = np.pad(\n    X_test,\n    pad_width=((0, 0), (0, pad_len), (0, 0)),\n    mode='constant',\n    constant_values=-np.inf\n)\n\n# Now X_train_padded has the shape (num_samples, 4370, 1).\n\n# Reshape to group every 5 consecutive elements:\n# New shape will be (num_samples, 874, 5, 1)\ngrouped_length = X_test_padded.shape[1] // 5  # Should be 874\nX_test_grouped = X_test_padded.reshape(num_samples, grouped_length, 5, channels)\n\n# Take the max over the 5 elements for each group (axis=2)\n# Resulting shape is (num_samples, 874, 1)\nX_test_max = np.max(X_test_grouped, axis=2)\n\n# Optionally, if your model expects inputs of shape (num_samples, 874),\n# reshape the array from (num_samples, 874, 1) to (num_samples, 874)\nX_test_final = X_test_max.reshape(num_samples, grouped_length)\n\n# Check the resulting shape\nprint(\"Shape after max-pooling and reshaping:\", X_test_final.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:04:43.794812Z","iopub.execute_input":"2025-02-12T09:04:43.795177Z","iopub.status.idle":"2025-02-12T09:04:43.828016Z","shell.execute_reply.started":"2025-02-12T09:04:43.795117Z","shell.execute_reply":"2025-02-12T09:04:43.827207Z"}},"outputs":[{"name":"stdout","text":"Shape after max-pooling and reshaping: (204, 874)\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the checkpoint callback to save every epoch\ncheckpoint_callback = ModelCheckpoint(\n    filepath='model_checkpoint.keras',  # Save file with epoch number and .keras extension\n    save_weights_only=False,  # Save the full model\n    save_freq='epoch',  # Save at the end of each epoch\n    verbose=1  # To print a message when the model is saved\n)\n\n# Modify the callbacks list to include the checkpoint callback \ncallbacks = [\n    keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True),\n    checkpoint_callback\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:04:48.005811Z","iopub.execute_input":"2025-02-12T09:04:48.006164Z","iopub.status.idle":"2025-02-12T09:04:48.013709Z","shell.execute_reply.started":"2025-02-12T09:04:48.006106Z","shell.execute_reply":"2025-02-12T09:04:48.012798Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"%pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:07:02.220413Z","iopub.execute_input":"2025-02-12T09:07:02.220746Z","iopub.status.idle":"2025-02-12T09:07:02.225812Z","shell.execute_reply.started":"2025-02-12T09:07:02.220719Z","shell.execute_reply":"2025-02-12T09:07:02.225071Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/ogw3-train-test'"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"os.chdir(\"..\")\nos.chdir(\"..\")\nos.chdir(\"working\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:07:31.642615Z","iopub.execute_input":"2025-02-12T09:07:31.642925Z","iopub.status.idle":"2025-02-12T09:07:31.647038Z","shell.execute_reply.started":"2025-02-12T09:07:31.642901Z","shell.execute_reply":"2025-02-12T09:07:31.646220Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"history = model.fit(\n    X_train_final,\n    y_train,\n    validation_data=(X_test_final, y_test),\n    epochs=200,\n    batch_size=32,\n    callbacks=callbacks,\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:07:34.743253Z","iopub.execute_input":"2025-02-12T09:07:34.743724Z","iopub.status.idle":"2025-02-12T12:45:53.042623Z","shell.execute_reply.started":"2025-02-12T09:07:34.743679Z","shell.execute_reply":"2025-02-12T12:45:53.041833Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2347 - loss: 2.5360\nEpoch 1: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.2344 - loss: 2.5370 - val_accuracy: 0.1569 - val_loss: 2.6258\nEpoch 2/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2212 - loss: 2.5263\nEpoch 2: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2215 - loss: 2.5260 - val_accuracy: 0.1667 - val_loss: 2.6179\nEpoch 3/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2290 - loss: 2.4968\nEpoch 3: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2292 - loss: 2.4969 - val_accuracy: 0.1667 - val_loss: 2.6044\nEpoch 4/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2588 - loss: 2.4388\nEpoch 4: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2586 - loss: 2.4391 - val_accuracy: 0.1569 - val_loss: 2.5913\nEpoch 5/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2408 - loss: 2.4671\nEpoch 5: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2409 - loss: 2.4672 - val_accuracy: 0.1765 - val_loss: 2.5712\nEpoch 6/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2551 - loss: 2.4320\nEpoch 6: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2550 - loss: 2.4319 - val_accuracy: 0.1765 - val_loss: 2.5623\nEpoch 7/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2373 - loss: 2.4329\nEpoch 7: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2375 - loss: 2.4332 - val_accuracy: 0.1667 - val_loss: 2.5485\nEpoch 8/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2450 - loss: 2.4325\nEpoch 8: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2451 - loss: 2.4325 - val_accuracy: 0.1765 - val_loss: 2.5449\nEpoch 9/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2593 - loss: 2.4061\nEpoch 9: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2592 - loss: 2.4066 - val_accuracy: 0.1765 - val_loss: 2.5467\nEpoch 10/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2702 - loss: 2.3863\nEpoch 10: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2699 - loss: 2.3865 - val_accuracy: 0.1765 - val_loss: 2.5483\nEpoch 11/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2659 - loss: 2.3755\nEpoch 11: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.2657 - loss: 2.3759 - val_accuracy: 0.1765 - val_loss: 2.5214\nEpoch 12/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2494 - loss: 2.4022\nEpoch 12: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2495 - loss: 2.4018 - val_accuracy: 0.1569 - val_loss: 2.5311\nEpoch 13/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2597 - loss: 2.3880\nEpoch 13: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2597 - loss: 2.3881 - val_accuracy: 0.1863 - val_loss: 2.5124\nEpoch 14/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2483 - loss: 2.3991\nEpoch 14: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2482 - loss: 2.3991 - val_accuracy: 0.1961 - val_loss: 2.5017\nEpoch 15/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2528 - loss: 2.3603\nEpoch 15: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2530 - loss: 2.3603 - val_accuracy: 0.1863 - val_loss: 2.5099\nEpoch 16/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2852 - loss: 2.3207\nEpoch 16: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2849 - loss: 2.3213 - val_accuracy: 0.1863 - val_loss: 2.5090\nEpoch 17/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2727 - loss: 2.3518\nEpoch 17: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2727 - loss: 2.3517 - val_accuracy: 0.1961 - val_loss: 2.4975\nEpoch 18/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2804 - loss: 2.3240\nEpoch 18: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2804 - loss: 2.3239 - val_accuracy: 0.1667 - val_loss: 2.4773\nEpoch 19/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2573 - loss: 2.3429\nEpoch 19: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2575 - loss: 2.3427 - val_accuracy: 0.2059 - val_loss: 2.4952\nEpoch 20/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3019 - loss: 2.2776\nEpoch 20: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3009 - loss: 2.2789 - val_accuracy: 0.1961 - val_loss: 2.4638\nEpoch 21/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2504 - loss: 2.3350\nEpoch 21: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2505 - loss: 2.3350 - val_accuracy: 0.1863 - val_loss: 2.4980\nEpoch 22/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2771 - loss: 2.3220\nEpoch 22: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2771 - loss: 2.3222 - val_accuracy: 0.1961 - val_loss: 2.4642\nEpoch 23/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2694 - loss: 2.3021\nEpoch 23: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2692 - loss: 2.3025 - val_accuracy: 0.1863 - val_loss: 2.4508\nEpoch 24/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2840 - loss: 2.2990\nEpoch 24: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2837 - loss: 2.2994 - val_accuracy: 0.1961 - val_loss: 2.4463\nEpoch 25/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2699 - loss: 2.3152\nEpoch 25: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2700 - loss: 2.3148 - val_accuracy: 0.2255 - val_loss: 2.4582\nEpoch 26/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2673 - loss: 2.3140\nEpoch 26: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2672 - loss: 2.3140 - val_accuracy: 0.2157 - val_loss: 2.4532\nEpoch 27/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2523 - loss: 2.3409\nEpoch 27: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2525 - loss: 2.3402 - val_accuracy: 0.2059 - val_loss: 2.4534\nEpoch 28/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2686 - loss: 2.2880\nEpoch 28: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2686 - loss: 2.2882 - val_accuracy: 0.2059 - val_loss: 2.4377\nEpoch 29/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2714 - loss: 2.2824\nEpoch 29: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2718 - loss: 2.2822 - val_accuracy: 0.1863 - val_loss: 2.4403\nEpoch 30/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2741 - loss: 2.2803\nEpoch 30: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2739 - loss: 2.2808 - val_accuracy: 0.1961 - val_loss: 2.4295\nEpoch 31/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2796 - loss: 2.2447\nEpoch 31: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2795 - loss: 2.2453 - val_accuracy: 0.1961 - val_loss: 2.4399\nEpoch 32/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2710 - loss: 2.2841\nEpoch 32: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2711 - loss: 2.2840 - val_accuracy: 0.2059 - val_loss: 2.4169\nEpoch 33/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2915 - loss: 2.2558\nEpoch 33: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2913 - loss: 2.2562 - val_accuracy: 0.2255 - val_loss: 2.4091\nEpoch 34/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2650 - loss: 2.2572\nEpoch 34: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2654 - loss: 2.2570 - val_accuracy: 0.2157 - val_loss: 2.4096\nEpoch 35/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2768 - loss: 2.2505\nEpoch 35: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2771 - loss: 2.2498 - val_accuracy: 0.2059 - val_loss: 2.4008\nEpoch 36/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2923 - loss: 2.2172\nEpoch 36: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2920 - loss: 2.2178 - val_accuracy: 0.2353 - val_loss: 2.4059\nEpoch 37/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3029 - loss: 2.2043\nEpoch 37: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3023 - loss: 2.2051 - val_accuracy: 0.2059 - val_loss: 2.3935\nEpoch 38/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2990 - loss: 2.2239\nEpoch 38: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2989 - loss: 2.2239 - val_accuracy: 0.2255 - val_loss: 2.3753\nEpoch 39/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2809 - loss: 2.2442\nEpoch 39: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2811 - loss: 2.2438 - val_accuracy: 0.2059 - val_loss: 2.3855\nEpoch 40/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2974 - loss: 2.2083\nEpoch 40: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2974 - loss: 2.2086 - val_accuracy: 0.2059 - val_loss: 2.3935\nEpoch 41/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2889 - loss: 2.1979\nEpoch 41: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2890 - loss: 2.1981 - val_accuracy: 0.2157 - val_loss: 2.3869\nEpoch 42/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3007 - loss: 2.1800\nEpoch 42: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3004 - loss: 2.1807 - val_accuracy: 0.2353 - val_loss: 2.3823\nEpoch 43/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2937 - loss: 2.1904\nEpoch 43: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2937 - loss: 2.1903 - val_accuracy: 0.2157 - val_loss: 2.3895\nEpoch 44/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2768 - loss: 2.2114\nEpoch 44: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2770 - loss: 2.2115 - val_accuracy: 0.2451 - val_loss: 2.3645\nEpoch 45/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3021 - loss: 2.1955\nEpoch 45: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3018 - loss: 2.1959 - val_accuracy: 0.2255 - val_loss: 2.3704\nEpoch 46/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2968 - loss: 2.1931\nEpoch 46: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2969 - loss: 2.1929 - val_accuracy: 0.2353 - val_loss: 2.3868\nEpoch 47/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2903 - loss: 2.1973\nEpoch 47: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.2902 - loss: 2.1974 - val_accuracy: 0.2353 - val_loss: 2.3794\nEpoch 48/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3009 - loss: 2.1659\nEpoch 48: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3010 - loss: 2.1661 - val_accuracy: 0.2353 - val_loss: 2.3578\nEpoch 49/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3102 - loss: 2.1448\nEpoch 49: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3098 - loss: 2.1455 - val_accuracy: 0.2059 - val_loss: 2.3608\nEpoch 50/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2916 - loss: 2.1762\nEpoch 50: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2920 - loss: 2.1759 - val_accuracy: 0.2157 - val_loss: 2.3836\nEpoch 51/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3006 - loss: 2.1476\nEpoch 51: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3005 - loss: 2.1481 - val_accuracy: 0.2157 - val_loss: 2.3497\nEpoch 52/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3061 - loss: 2.1618\nEpoch 52: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3062 - loss: 2.1617 - val_accuracy: 0.2255 - val_loss: 2.3452\nEpoch 53/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3160 - loss: 2.1303\nEpoch 53: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3159 - loss: 2.1306 - val_accuracy: 0.2255 - val_loss: 2.3477\nEpoch 54/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3281 - loss: 2.0973\nEpoch 54: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3277 - loss: 2.0983 - val_accuracy: 0.2255 - val_loss: 2.3412\nEpoch 55/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3236 - loss: 2.1081\nEpoch 55: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3235 - loss: 2.1085 - val_accuracy: 0.2255 - val_loss: 2.3433\nEpoch 56/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3195 - loss: 2.0972\nEpoch 56: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3192 - loss: 2.0980 - val_accuracy: 0.2353 - val_loss: 2.3630\nEpoch 57/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3087 - loss: 2.1004\nEpoch 57: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3087 - loss: 2.1010 - val_accuracy: 0.2353 - val_loss: 2.3325\nEpoch 58/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3138 - loss: 2.1579\nEpoch 58: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3141 - loss: 2.1570 - val_accuracy: 0.2451 - val_loss: 2.3339\nEpoch 59/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3053 - loss: 2.1335\nEpoch 59: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3057 - loss: 2.1330 - val_accuracy: 0.2451 - val_loss: 2.3339\nEpoch 60/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3357 - loss: 2.0623\nEpoch 60: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3354 - loss: 2.0633 - val_accuracy: 0.2157 - val_loss: 2.3520\nEpoch 61/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3310 - loss: 2.0598\nEpoch 61: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3308 - loss: 2.0605 - val_accuracy: 0.2451 - val_loss: 2.2946\nEpoch 62/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3446 - loss: 2.0667\nEpoch 62: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3442 - loss: 2.0673 - val_accuracy: 0.2451 - val_loss: 2.3221\nEpoch 63/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3410 - loss: 2.0899\nEpoch 63: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3412 - loss: 2.0894 - val_accuracy: 0.2353 - val_loss: 2.3358\nEpoch 64/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3182 - loss: 2.0902\nEpoch 64: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3183 - loss: 2.0901 - val_accuracy: 0.2451 - val_loss: 2.3030\nEpoch 65/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3189 - loss: 2.1001\nEpoch 65: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3190 - loss: 2.0997 - val_accuracy: 0.2451 - val_loss: 2.3205\nEpoch 66/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3435 - loss: 2.0522\nEpoch 66: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3438 - loss: 2.0516 - val_accuracy: 0.2451 - val_loss: 2.3253\nEpoch 67/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3462 - loss: 2.0389\nEpoch 67: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3462 - loss: 2.0392 - val_accuracy: 0.2451 - val_loss: 2.2981\nEpoch 68/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3359 - loss: 2.0562\nEpoch 68: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3360 - loss: 2.0562 - val_accuracy: 0.2647 - val_loss: 2.3011\nEpoch 69/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3361 - loss: 2.0490\nEpoch 69: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3363 - loss: 2.0492 - val_accuracy: 0.2353 - val_loss: 2.2864\nEpoch 70/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3557 - loss: 2.0183\nEpoch 70: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3554 - loss: 2.0192 - val_accuracy: 0.2353 - val_loss: 2.3171\nEpoch 71/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3379 - loss: 2.0399\nEpoch 71: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3381 - loss: 2.0395 - val_accuracy: 0.2451 - val_loss: 2.2996\nEpoch 72/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3386 - loss: 2.0501\nEpoch 72: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3388 - loss: 2.0494 - val_accuracy: 0.2549 - val_loss: 2.2700\nEpoch 73/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3506 - loss: 2.0277\nEpoch 73: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3505 - loss: 2.0277 - val_accuracy: 0.2549 - val_loss: 2.2780\nEpoch 74/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3531 - loss: 2.0186\nEpoch 74: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3531 - loss: 2.0184 - val_accuracy: 0.2353 - val_loss: 2.2779\nEpoch 75/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3687 - loss: 2.0127\nEpoch 75: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3687 - loss: 2.0121 - val_accuracy: 0.2549 - val_loss: 2.2418\nEpoch 76/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3599 - loss: 2.0046\nEpoch 76: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3602 - loss: 2.0044 - val_accuracy: 0.2549 - val_loss: 2.2733\nEpoch 77/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3701 - loss: 1.9859\nEpoch 77: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3702 - loss: 1.9857 - val_accuracy: 0.2549 - val_loss: 2.2617\nEpoch 78/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3427 - loss: 1.9971\nEpoch 78: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3428 - loss: 1.9974 - val_accuracy: 0.2451 - val_loss: 2.2761\nEpoch 79/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3521 - loss: 1.9963\nEpoch 79: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3521 - loss: 1.9964 - val_accuracy: 0.2549 - val_loss: 2.2388\nEpoch 80/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3648 - loss: 2.0015\nEpoch 80: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3648 - loss: 2.0014 - val_accuracy: 0.2549 - val_loss: 2.2650\nEpoch 81/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3737 - loss: 1.9546\nEpoch 81: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3739 - loss: 1.9542 - val_accuracy: 0.2157 - val_loss: 2.2483\nEpoch 82/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3752 - loss: 1.9780\nEpoch 82: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3752 - loss: 1.9780 - val_accuracy: 0.2451 - val_loss: 2.2416\nEpoch 83/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3815 - loss: 1.9795\nEpoch 83: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3817 - loss: 1.9790 - val_accuracy: 0.2745 - val_loss: 2.2476\nEpoch 84/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3856 - loss: 1.9343\nEpoch 84: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3851 - loss: 1.9351 - val_accuracy: 0.2647 - val_loss: 2.2331\nEpoch 85/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3737 - loss: 1.9519\nEpoch 85: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3735 - loss: 1.9521 - val_accuracy: 0.2549 - val_loss: 2.2479\nEpoch 86/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3967 - loss: 1.9596\nEpoch 86: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3961 - loss: 1.9602 - val_accuracy: 0.2451 - val_loss: 2.2531\nEpoch 87/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3821 - loss: 1.9707\nEpoch 87: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3820 - loss: 1.9705 - val_accuracy: 0.2549 - val_loss: 2.2521\nEpoch 88/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4021 - loss: 1.8683\nEpoch 88: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4016 - loss: 1.8694 - val_accuracy: 0.2549 - val_loss: 2.2306\nEpoch 89/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3957 - loss: 1.9082\nEpoch 89: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3954 - loss: 1.9092 - val_accuracy: 0.2549 - val_loss: 2.2280\nEpoch 90/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4035 - loss: 1.9194\nEpoch 90: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4032 - loss: 1.9197 - val_accuracy: 0.2549 - val_loss: 2.2235\nEpoch 91/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3879 - loss: 1.9517\nEpoch 91: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3882 - loss: 1.9509 - val_accuracy: 0.2549 - val_loss: 2.2184\nEpoch 92/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3751 - loss: 1.9309\nEpoch 92: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3750 - loss: 1.9309 - val_accuracy: 0.2647 - val_loss: 2.2325\nEpoch 93/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3888 - loss: 1.9004\nEpoch 93: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3889 - loss: 1.9007 - val_accuracy: 0.2745 - val_loss: 2.2166\nEpoch 94/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4310 - loss: 1.8492\nEpoch 94: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4305 - loss: 1.8502 - val_accuracy: 0.2647 - val_loss: 2.1886\nEpoch 95/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4254 - loss: 1.8667\nEpoch 95: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4252 - loss: 1.8670 - val_accuracy: 0.2549 - val_loss: 2.2155\nEpoch 96/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4256 - loss: 1.8482\nEpoch 96: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4254 - loss: 1.8488 - val_accuracy: 0.2843 - val_loss: 2.2050\nEpoch 97/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4059 - loss: 1.8803\nEpoch 97: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4061 - loss: 1.8801 - val_accuracy: 0.2549 - val_loss: 2.2155\nEpoch 98/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4020 - loss: 1.8746\nEpoch 98: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4026 - loss: 1.8737 - val_accuracy: 0.2647 - val_loss: 2.1966\nEpoch 99/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4143 - loss: 1.8855\nEpoch 99: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4144 - loss: 1.8852 - val_accuracy: 0.2647 - val_loss: 2.1973\nEpoch 100/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4050 - loss: 1.8792\nEpoch 100: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4052 - loss: 1.8791 - val_accuracy: 0.2451 - val_loss: 2.1893\nEpoch 101/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4329 - loss: 1.8169\nEpoch 101: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4329 - loss: 1.8174 - val_accuracy: 0.3039 - val_loss: 2.1738\nEpoch 102/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4272 - loss: 1.8251\nEpoch 102: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4270 - loss: 1.8257 - val_accuracy: 0.2647 - val_loss: 2.1694\nEpoch 103/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4172 - loss: 1.8323\nEpoch 103: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4173 - loss: 1.8323 - val_accuracy: 0.2549 - val_loss: 2.1860\nEpoch 104/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3911 - loss: 1.8572\nEpoch 104: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.3915 - loss: 1.8569 - val_accuracy: 0.2549 - val_loss: 2.1993\nEpoch 105/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4285 - loss: 1.7870\nEpoch 105: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4284 - loss: 1.7880 - val_accuracy: 0.2647 - val_loss: 2.1589\nEpoch 106/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4474 - loss: 1.8218\nEpoch 106: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4473 - loss: 1.8215 - val_accuracy: 0.2745 - val_loss: 2.1640\nEpoch 107/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4642 - loss: 1.7870\nEpoch 107: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4640 - loss: 1.7874 - val_accuracy: 0.3137 - val_loss: 2.1551\nEpoch 108/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4235 - loss: 1.8330\nEpoch 108: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4237 - loss: 1.8330 - val_accuracy: 0.2843 - val_loss: 2.1660\nEpoch 109/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4469 - loss: 1.7772\nEpoch 109: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4470 - loss: 1.7775 - val_accuracy: 0.2745 - val_loss: 2.1562\nEpoch 110/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4488 - loss: 1.7819\nEpoch 110: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4488 - loss: 1.7823 - val_accuracy: 0.3137 - val_loss: 2.1525\nEpoch 111/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4749 - loss: 1.7936\nEpoch 111: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4747 - loss: 1.7936 - val_accuracy: 0.2941 - val_loss: 2.1485\nEpoch 112/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4616 - loss: 1.7833\nEpoch 112: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4617 - loss: 1.7829 - val_accuracy: 0.3137 - val_loss: 2.1592\nEpoch 113/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4729 - loss: 1.7579\nEpoch 113: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4724 - loss: 1.7584 - val_accuracy: 0.2745 - val_loss: 2.1335\nEpoch 114/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4413 - loss: 1.7823\nEpoch 114: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4413 - loss: 1.7826 - val_accuracy: 0.3137 - val_loss: 2.1233\nEpoch 115/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4583 - loss: 1.7937\nEpoch 115: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4580 - loss: 1.7938 - val_accuracy: 0.2745 - val_loss: 2.1679\nEpoch 116/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4622 - loss: 1.7314\nEpoch 116: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4624 - loss: 1.7312 - val_accuracy: 0.2843 - val_loss: 2.1440\nEpoch 117/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4890 - loss: 1.7347\nEpoch 117: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4886 - loss: 1.7348 - val_accuracy: 0.3137 - val_loss: 2.1317\nEpoch 118/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4597 - loss: 1.7294\nEpoch 118: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4594 - loss: 1.7297 - val_accuracy: 0.2745 - val_loss: 2.1417\nEpoch 119/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4762 - loss: 1.7327\nEpoch 119: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4762 - loss: 1.7326 - val_accuracy: 0.2843 - val_loss: 2.1194\nEpoch 120/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4868 - loss: 1.7319\nEpoch 120: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4871 - loss: 1.7315 - val_accuracy: 0.3039 - val_loss: 2.1195\nEpoch 121/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4750 - loss: 1.7222\nEpoch 121: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4752 - loss: 1.7220 - val_accuracy: 0.2941 - val_loss: 2.1281\nEpoch 122/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4758 - loss: 1.7096\nEpoch 122: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.4755 - loss: 1.7097 - val_accuracy: 0.2745 - val_loss: 2.1273\nEpoch 123/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4762 - loss: 1.6937\nEpoch 123: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4760 - loss: 1.6946 - val_accuracy: 0.3137 - val_loss: 2.1166\nEpoch 124/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4860 - loss: 1.7242\nEpoch 124: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4859 - loss: 1.7240 - val_accuracy: 0.2647 - val_loss: 2.1084\nEpoch 125/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4941 - loss: 1.6646\nEpoch 125: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4942 - loss: 1.6647 - val_accuracy: 0.2941 - val_loss: 2.0983\nEpoch 126/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4840 - loss: 1.7211\nEpoch 126: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4839 - loss: 1.7210 - val_accuracy: 0.2843 - val_loss: 2.1060\nEpoch 127/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4900 - loss: 1.6810\nEpoch 127: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4901 - loss: 1.6815 - val_accuracy: 0.2941 - val_loss: 2.0716\nEpoch 128/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5078 - loss: 1.6437\nEpoch 128: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5078 - loss: 1.6436 - val_accuracy: 0.2843 - val_loss: 2.1142\nEpoch 129/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4769 - loss: 1.6577\nEpoch 129: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4768 - loss: 1.6578 - val_accuracy: 0.2745 - val_loss: 2.0848\nEpoch 130/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4978 - loss: 1.6626\nEpoch 130: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4977 - loss: 1.6630 - val_accuracy: 0.2843 - val_loss: 2.0975\nEpoch 131/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4890 - loss: 1.6825\nEpoch 131: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4894 - loss: 1.6824 - val_accuracy: 0.3333 - val_loss: 2.0712\nEpoch 132/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4968 - loss: 1.6618\nEpoch 132: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.4965 - loss: 1.6624 - val_accuracy: 0.2843 - val_loss: 2.0860\nEpoch 133/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5161 - loss: 1.6344\nEpoch 133: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5161 - loss: 1.6348 - val_accuracy: 0.2647 - val_loss: 2.0754\nEpoch 134/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4982 - loss: 1.6790\nEpoch 134: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4980 - loss: 1.6793 - val_accuracy: 0.2843 - val_loss: 2.0691\nEpoch 135/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5096 - loss: 1.6197\nEpoch 135: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5096 - loss: 1.6202 - val_accuracy: 0.2941 - val_loss: 2.0544\nEpoch 136/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5116 - loss: 1.6130\nEpoch 136: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5117 - loss: 1.6135 - val_accuracy: 0.2941 - val_loss: 2.0764\nEpoch 137/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5182 - loss: 1.6047\nEpoch 137: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5183 - loss: 1.6051 - val_accuracy: 0.3137 - val_loss: 2.0645\nEpoch 138/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5313 - loss: 1.6305\nEpoch 138: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5315 - loss: 1.6299 - val_accuracy: 0.3137 - val_loss: 2.0661\nEpoch 139/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5163 - loss: 1.6212\nEpoch 139: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5163 - loss: 1.6213 - val_accuracy: 0.2843 - val_loss: 2.0728\nEpoch 140/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5346 - loss: 1.6004\nEpoch 140: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5344 - loss: 1.6007 - val_accuracy: 0.3235 - val_loss: 2.0298\nEpoch 141/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5307 - loss: 1.6194\nEpoch 141: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5304 - loss: 1.6192 - val_accuracy: 0.3333 - val_loss: 2.0674\nEpoch 142/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5286 - loss: 1.5753\nEpoch 142: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5285 - loss: 1.5757 - val_accuracy: 0.2843 - val_loss: 2.0572\nEpoch 143/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5391 - loss: 1.5746\nEpoch 143: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5385 - loss: 1.5751 - val_accuracy: 0.3039 - val_loss: 2.0677\nEpoch 144/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5185 - loss: 1.6293\nEpoch 144: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5187 - loss: 1.6287 - val_accuracy: 0.3333 - val_loss: 2.0703\nEpoch 145/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5537 - loss: 1.5536\nEpoch 145: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5535 - loss: 1.5535 - val_accuracy: 0.3333 - val_loss: 2.0368\nEpoch 146/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5686 - loss: 1.5612\nEpoch 146: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5684 - loss: 1.5610 - val_accuracy: 0.2843 - val_loss: 2.0472\nEpoch 147/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5352 - loss: 1.5606\nEpoch 147: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5349 - loss: 1.5612 - val_accuracy: 0.3039 - val_loss: 2.0277\nEpoch 148/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5642 - loss: 1.5318\nEpoch 148: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5638 - loss: 1.5322 - val_accuracy: 0.3333 - val_loss: 2.0122\nEpoch 149/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5389 - loss: 1.5651\nEpoch 149: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5392 - loss: 1.5645 - val_accuracy: 0.2941 - val_loss: 2.0324\nEpoch 150/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5378 - loss: 1.5612\nEpoch 150: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5382 - loss: 1.5610 - val_accuracy: 0.3333 - val_loss: 2.0211\nEpoch 151/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5262 - loss: 1.5554\nEpoch 151: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5267 - loss: 1.5550 - val_accuracy: 0.2941 - val_loss: 2.0381\nEpoch 152/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5370 - loss: 1.5337\nEpoch 152: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5375 - loss: 1.5332 - val_accuracy: 0.3235 - val_loss: 2.0210\nEpoch 153/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5604 - loss: 1.5459\nEpoch 153: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5603 - loss: 1.5458 - val_accuracy: 0.3431 - val_loss: 2.0081\nEpoch 154/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5668 - loss: 1.5272\nEpoch 154: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5669 - loss: 1.5269 - val_accuracy: 0.3431 - val_loss: 2.0324\nEpoch 155/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5721 - loss: 1.4805\nEpoch 155: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5717 - loss: 1.4813 - val_accuracy: 0.3235 - val_loss: 2.0020\nEpoch 156/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5850 - loss: 1.5012\nEpoch 156: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5847 - loss: 1.5014 - val_accuracy: 0.3235 - val_loss: 2.0062\nEpoch 157/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5637 - loss: 1.4820\nEpoch 157: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5636 - loss: 1.4823 - val_accuracy: 0.2941 - val_loss: 2.0148\nEpoch 158/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5974 - loss: 1.4831\nEpoch 158: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5969 - loss: 1.4836 - val_accuracy: 0.3431 - val_loss: 2.0135\nEpoch 159/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5847 - loss: 1.4807\nEpoch 159: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5844 - loss: 1.4810 - val_accuracy: 0.4118 - val_loss: 1.9893\nEpoch 160/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5787 - loss: 1.5062\nEpoch 160: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5784 - loss: 1.5066 - val_accuracy: 0.3137 - val_loss: 2.0264\nEpoch 161/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5663 - loss: 1.5192\nEpoch 161: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5665 - loss: 1.5183 - val_accuracy: 0.3235 - val_loss: 1.9981\nEpoch 162/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5814 - loss: 1.4458\nEpoch 162: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5814 - loss: 1.4462 - val_accuracy: 0.3725 - val_loss: 1.9724\nEpoch 163/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5959 - loss: 1.4537\nEpoch 163: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5954 - loss: 1.4545 - val_accuracy: 0.3333 - val_loss: 1.9832\nEpoch 164/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5726 - loss: 1.4605\nEpoch 164: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5726 - loss: 1.4607 - val_accuracy: 0.3137 - val_loss: 1.9813\nEpoch 165/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5862 - loss: 1.4474\nEpoch 165: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5862 - loss: 1.4473 - val_accuracy: 0.3627 - val_loss: 1.9862\nEpoch 166/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6063 - loss: 1.4259\nEpoch 166: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6060 - loss: 1.4265 - val_accuracy: 0.3431 - val_loss: 1.9543\nEpoch 167/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5962 - loss: 1.4559\nEpoch 167: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5956 - loss: 1.4560 - val_accuracy: 0.3431 - val_loss: 1.9580\nEpoch 168/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5969 - loss: 1.4298\nEpoch 168: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5964 - loss: 1.4303 - val_accuracy: 0.3431 - val_loss: 1.9791\nEpoch 169/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6307 - loss: 1.3710\nEpoch 169: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6305 - loss: 1.3714 - val_accuracy: 0.3725 - val_loss: 1.9617\nEpoch 170/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6164 - loss: 1.4202\nEpoch 170: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6160 - loss: 1.4206 - val_accuracy: 0.3725 - val_loss: 1.9540\nEpoch 171/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6154 - loss: 1.4097\nEpoch 171: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6156 - loss: 1.4097 - val_accuracy: 0.3627 - val_loss: 1.9556\nEpoch 172/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5967 - loss: 1.4268\nEpoch 172: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.5966 - loss: 1.4267 - val_accuracy: 0.3922 - val_loss: 1.9524\nEpoch 173/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6171 - loss: 1.4000\nEpoch 173: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6170 - loss: 1.3999 - val_accuracy: 0.3529 - val_loss: 1.9669\nEpoch 174/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6134 - loss: 1.3896\nEpoch 174: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6127 - loss: 1.3907 - val_accuracy: 0.3922 - val_loss: 1.9595\nEpoch 175/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6131 - loss: 1.3738\nEpoch 175: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6129 - loss: 1.3744 - val_accuracy: 0.3824 - val_loss: 1.9374\nEpoch 176/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6238 - loss: 1.3997\nEpoch 176: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6233 - loss: 1.4007 - val_accuracy: 0.3235 - val_loss: 1.9761\nEpoch 177/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5970 - loss: 1.4267\nEpoch 177: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5967 - loss: 1.4271 - val_accuracy: 0.3333 - val_loss: 1.9345\nEpoch 178/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6191 - loss: 1.3699\nEpoch 178: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6189 - loss: 1.3705 - val_accuracy: 0.3627 - val_loss: 1.9346\nEpoch 179/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6312 - loss: 1.3730\nEpoch 179: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6311 - loss: 1.3729 - val_accuracy: 0.3137 - val_loss: 1.9412\nEpoch 180/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6073 - loss: 1.3509\nEpoch 180: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6072 - loss: 1.3513 - val_accuracy: 0.3824 - val_loss: 1.9342\nEpoch 181/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6419 - loss: 1.3564\nEpoch 181: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6420 - loss: 1.3562 - val_accuracy: 0.3627 - val_loss: 1.9482\nEpoch 182/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6376 - loss: 1.3533\nEpoch 182: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6375 - loss: 1.3535 - val_accuracy: 0.3235 - val_loss: 1.9463\nEpoch 183/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6175 - loss: 1.3533\nEpoch 183: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6176 - loss: 1.3533 - val_accuracy: 0.3725 - val_loss: 1.9096\nEpoch 184/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6422 - loss: 1.3360\nEpoch 184: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6419 - loss: 1.3363 - val_accuracy: 0.3824 - val_loss: 1.9264\nEpoch 185/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6473 - loss: 1.3183\nEpoch 185: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6472 - loss: 1.3182 - val_accuracy: 0.3824 - val_loss: 1.9113\nEpoch 186/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6433 - loss: 1.3466\nEpoch 186: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6433 - loss: 1.3465 - val_accuracy: 0.3824 - val_loss: 1.9311\nEpoch 187/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6509 - loss: 1.3134\nEpoch 187: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6505 - loss: 1.3142 - val_accuracy: 0.3333 - val_loss: 1.9535\nEpoch 188/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6132 - loss: 1.3396\nEpoch 188: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6136 - loss: 1.3395 - val_accuracy: 0.3824 - val_loss: 1.9199\nEpoch 189/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6461 - loss: 1.3448\nEpoch 189: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6460 - loss: 1.3446 - val_accuracy: 0.3725 - val_loss: 1.9062\nEpoch 190/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6507 - loss: 1.3136\nEpoch 190: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6505 - loss: 1.3137 - val_accuracy: 0.3235 - val_loss: 1.9377\nEpoch 191/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6474 - loss: 1.2938\nEpoch 191: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6477 - loss: 1.2933 - val_accuracy: 0.3333 - val_loss: 1.9190\nEpoch 192/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6495 - loss: 1.3258\nEpoch 192: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6494 - loss: 1.3256 - val_accuracy: 0.3039 - val_loss: 1.9304\nEpoch 193/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6503 - loss: 1.2776\nEpoch 193: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6500 - loss: 1.2783 - val_accuracy: 0.3824 - val_loss: 1.8981\nEpoch 194/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6718 - loss: 1.2651\nEpoch 194: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6714 - loss: 1.2655 - val_accuracy: 0.3725 - val_loss: 1.9079\nEpoch 195/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6461 - loss: 1.2836\nEpoch 195: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6460 - loss: 1.2838 - val_accuracy: 0.4020 - val_loss: 1.8960\nEpoch 196/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6535 - loss: 1.2402\nEpoch 196: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6537 - loss: 1.2407 - val_accuracy: 0.3431 - val_loss: 1.9226\nEpoch 197/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6682 - loss: 1.2660\nEpoch 197: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6680 - loss: 1.2661 - val_accuracy: 0.3725 - val_loss: 1.8929\nEpoch 198/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6617 - loss: 1.2761\nEpoch 198: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6616 - loss: 1.2761 - val_accuracy: 0.4020 - val_loss: 1.8874\nEpoch 199/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6632 - loss: 1.2465\nEpoch 199: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6634 - loss: 1.2464 - val_accuracy: 0.4020 - val_loss: 1.9332\nEpoch 200/200\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6873 - loss: 1.2310\nEpoch 200: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6865 - loss: 1.2321 - val_accuracy: 0.4216 - val_loss: 1.8907\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"# 4. Model Evaluation #","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:20:29.622013Z","iopub.execute_input":"2025-02-11T06:20:29.622424Z","iopub.status.idle":"2025-02-11T06:20:29.626868Z","shell.execute_reply.started":"2025-02-11T06:20:29.622388Z","shell.execute_reply":"2025-02-11T06:20:29.625852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assume y_pred_norm are the predictions from your model (normalized)\ny_pred_norm = model.predict(X_test).flatten()\n\n# Convert normalized predictions back to the original scale.\ny_pred = y_pred_norm * (y_max - y_min) + y_min\n\nprint(\"Predictions in the original scale (first 5):\", y_pred[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:21:21.363852Z","iopub.execute_input":"2025-02-11T06:21:21.364165Z","iopub.status.idle":"2025-02-11T06:21:21.885660Z","shell.execute_reply.started":"2025-02-11T06:21:21.364141Z","shell.execute_reply":"2025-02-11T06:21:21.884956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Make predictions\n# y_pred = model.predict(X_test).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:21:24.995370Z","iopub.execute_input":"2025-02-11T06:21:24.995671Z","iopub.status.idle":"2025-02-11T06:21:24.999269Z","shell.execute_reply.started":"2025-02-11T06:21:24.995648Z","shell.execute_reply":"2025-02-11T06:21:24.998442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:21:26.135103Z","iopub.execute_input":"2025-02-11T06:21:26.135431Z","iopub.status.idle":"2025-02-11T06:21:26.141765Z","shell.execute_reply.started":"2025-02-11T06:21:26.135402Z","shell.execute_reply":"2025-02-11T06:21:26.140849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"\"\"\nPerformance Metrics:\n- MAE: {mae:.3f}\n- MSE: {mse:.3f}\n- RMSE: {rmse:.3f}\n- R²: {r2:.3f}\n\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:21:29.975860Z","iopub.execute_input":"2025-02-11T06:21:29.976223Z","iopub.status.idle":"2025-02-11T06:21:29.983110Z","shell.execute_reply.started":"2025-02-11T06:21:29.976192Z","shell.execute_reply":"2025-02-11T06:21:29.982391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\nplt.plot([0,13], [0,13], 'r--')  # Perfect prediction line\nplt.xlabel('True Damage Size')\nplt.ylabel('Predicted Damage Size')\nplt.title('True vs Predicted Values')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:21:31.532505Z","iopub.execute_input":"2025-02-11T06:21:31.532795Z","iopub.status.idle":"2025-02-11T06:21:31.722472Z","shell.execute_reply.started":"2025-02-11T06:21:31.532773Z","shell.execute_reply":"2025-02-11T06:21:31.721742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"residuals = y_test - y_pred\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_pred, y=residuals, alpha=0.6)\nplt.axhline(y=0, color='r', linestyle='--')\nplt.xlabel('Predicted Values')\nplt.ylabel('Residuals')\nplt.title('Residual Analysis')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T05:51:14.776807Z","iopub.execute_input":"2025-02-11T05:51:14.777430Z","iopub.status.idle":"2025-02-11T05:51:14.966065Z","shell.execute_reply.started":"2025-02-11T05:51:14.777395Z","shell.execute_reply":"2025-02-11T05:51:14.965233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.histplot(residuals, kde=True, bins=20)\nplt.xlabel('Prediction Error')\nplt.title('Error Distribution')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T07:05:33.449862Z","iopub.execute_input":"2025-02-04T07:05:33.450274Z","iopub.status.idle":"2025-02-04T07:05:33.722080Z","shell.execute_reply.started":"2025-02-04T07:05:33.450241Z","shell.execute_reply":"2025-02-04T07:05:33.721211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"error_by_size = []\nfor size in np.unique(y_test):\n    mask = y_test == size\n    if sum(mask) > 0:  # Check if size exists in test set\n        size_mae = mean_absolute_error(y_test[mask], y_pred[mask])\n        error_by_size.append((size, size_mae))\n\n# Convert to DataFrame for better visualization\nimport pandas as pd\nerror_df = pd.DataFrame(error_by_size, columns=['Damage Size', 'MAE'])\nprint(\"\\nMAE by Damage Size:\")\nprint(error_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T07:05:44.500877Z","iopub.execute_input":"2025-02-04T07:05:44.501273Z","iopub.status.idle":"2025-02-04T07:05:44.545836Z","shell.execute_reply.started":"2025-02-04T07:05:44.501239Z","shell.execute_reply":"2025-02-04T07:05:44.545048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Separate baseline (label=0) and damage samples\nbaseline_mask = y_test == 0\ndamage_mask = y_test > 0\n\nprint(f\"\\nBaseline Performance (False Positives):\")\nprint(f\"- MAE: {mean_absolute_error(y_test[baseline_mask], y_pred[baseline_mask]):.3f}\")\n\nprint(f\"\\nDamage Performance:\")\nprint(f\"- MAE: {mean_absolute_error(y_test[damage_mask], y_pred[damage_mask]):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T07:05:52.776807Z","iopub.execute_input":"2025-02-04T07:05:52.777170Z","iopub.status.idle":"2025-02-04T07:05:52.784397Z","shell.execute_reply.started":"2025-02-04T07:05:52.777123Z","shell.execute_reply":"2025-02-04T07:05:52.783458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find samples with largest errors\nworst_indices = np.argsort(np.abs(residuals))[-5:]  # Top 5 worst predictions\n\nprint(\"\\nWorst Predictions:\")\nfor idx in worst_indices:\n    print(f\"True: {y_test[idx]:.1f}, Predicted: {y_pred[idx]:.2f}, Error: {residuals[idx]:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T07:05:56.037955Z","iopub.execute_input":"2025-02-04T07:05:56.038357Z","iopub.status.idle":"2025-02-04T07:05:56.044643Z","shell.execute_reply.started":"2025-02-04T07:05:56.038328Z","shell.execute_reply":"2025-02-04T07:05:56.043829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# simple baseline cnn model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:22:04.324755Z","iopub.execute_input":"2025-02-11T06:22:04.325038Z","iopub.status.idle":"2025-02-11T06:22:04.328680Z","shell.execute_reply.started":"2025-02-11T06:22:04.325015Z","shell.execute_reply":"2025-02-11T06:22:04.327722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_simple_cnn_model(input_shape=(4369, 1)):\n    \"\"\"\n    A simple baseline CNN for regression.\n    \"\"\"\n    inputs = layers.Input(shape=input_shape)\n    \n    # Block 1\n    x = layers.Conv1D(32, kernel_size=7, activation='relu', padding='same')(inputs)\n    x = layers.MaxPooling1D(pool_size=2)(x)  # Downsample by factor of 2\n    \n    # Block 2\n    x = layers.Conv1D(64, kernel_size=5, activation='relu', padding='same')(x)\n    x = layers.MaxPooling1D(pool_size=2)(x)  # Downsample further\n    \n    # Block 3\n    x = layers.Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)\n    x = layers.MaxPooling1D(pool_size=2)(x)\n    \n    # Global average pooling aggregates over the time dimension.\n    x = layers.GlobalAveragePooling1D()(x)\n    \n    # Fully-connected layers\n    x = layers.Dense(128, activation='relu')(x)\n    # x = layers.Dropout(0.3)(x)\n    outputs = layers.Dense(1, activation='linear')(x)\n    \n    model = models.Model(inputs, outputs)\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:31:19.541471Z","iopub.execute_input":"2025-02-11T06:31:19.541904Z","iopub.status.idle":"2025-02-11T06:31:19.550560Z","shell.execute_reply.started":"2025-02-11T06:31:19.541862Z","shell.execute_reply":"2025-02-11T06:31:19.549516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build and compile the model.\nmodel_simple = build_simple_cnn_model()\nmodel_simple.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='mse',  # Mean Squared Error loss for regression\n    metrics=['mae', 'mse']\n)\n\nmodel_simple.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:31:20.966366Z","iopub.execute_input":"2025-02-11T06:31:20.966688Z","iopub.status.idle":"2025-02-11T06:31:21.027496Z","shell.execute_reply.started":"2025-02-11T06:31:20.966660Z","shell.execute_reply":"2025-02-11T06:31:21.026853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n\n# Train the model.\nhistory_simple = model_simple.fit(\n    X_train, y_train,  # Use your training data (ensure y_train is the target extent of damage)\n    validation_data=(X_test, y_test),\n    epochs=100,\n    batch_size=32,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=10,\n            restore_best_weights=True\n        )\n    ]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:23:01.347290Z","iopub.execute_input":"2025-02-11T06:23:01.347641Z","iopub.status.idle":"2025-02-11T06:25:15.216633Z","shell.execute_reply.started":"2025-02-11T06:23:01.347614Z","shell.execute_reply":"2025-02-11T06:25:15.215825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training and validation loss\nplt.figure(figsize=(10, 5))\nplt.plot(history_simple.history['loss'], label='Train Loss')\nplt.plot(history_simple.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss (MSE)')\nplt.legend()\nplt.title('Training vs. Validation Loss')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:25:27.321722Z","iopub.execute_input":"2025-02-11T06:25:27.322043Z","iopub.status.idle":"2025-02-11T06:25:27.505203Z","shell.execute_reply.started":"2025-02-11T06:25:27.322019Z","shell.execute_reply":"2025-02-11T06:25:27.504491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use only a small subset of the training data\nsmall_X_train = X_train[:20]\nsmall_y_train =y_train[:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:31:44.429722Z","iopub.execute_input":"2025-02-11T06:31:44.430011Z","iopub.status.idle":"2025-02-11T06:31:44.433696Z","shell.execute_reply.started":"2025-02-11T06:31:44.429986Z","shell.execute_reply":"2025-02-11T06:31:44.432867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"small_y_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:31:52.939457Z","iopub.execute_input":"2025-02-11T06:31:52.939753Z","iopub.status.idle":"2025-02-11T06:31:52.944950Z","shell.execute_reply.started":"2025-02-11T06:31:52.939730Z","shell.execute_reply":"2025-02-11T06:31:52.944239Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n\nhistory_small = model_simple.fit(\n    small_X_train, small_y_train,\n    epochs=100,\n    batch_size=8,\n    verbose=1\n)\n\n# Evaluate on the small subset\nsmall_loss = model_simple.evaluate(small_X_train, small_y_train)\nprint(\"Loss on small subset:\", small_loss)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:31:57.032018Z","iopub.execute_input":"2025-02-11T06:31:57.032314Z","iopub.status.idle":"2025-02-11T06:32:05.703577Z","shell.execute_reply.started":"2025-02-11T06:31:57.032290Z","shell.execute_reply":"2025-02-11T06:32:05.702833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Make predictions\ny_pred_small = model_simple.predict(small_X_train).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:33:59.923891Z","iopub.execute_input":"2025-02-11T06:33:59.924185Z","iopub.status.idle":"2025-02-11T06:34:00.251697Z","shell.execute_reply.started":"2025-02-11T06:33:59.924161Z","shell.execute_reply":"2025-02-11T06:34:00.251046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_small","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:34:01.829832Z","iopub.execute_input":"2025-02-11T06:34:01.830132Z","iopub.status.idle":"2025-02-11T06:34:01.835451Z","shell.execute_reply.started":"2025-02-11T06:34:01.830109Z","shell.execute_reply":"2025-02-11T06:34:01.834735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"try converting it again to a classification problem, and see if the model is able to learn any notable patterns","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}