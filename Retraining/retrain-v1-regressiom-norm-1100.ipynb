{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10709822,"sourceType":"datasetVersion","datasetId":6637708},{"sourceId":258296,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":220767,"modelId":242542},{"sourceId":258919,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":221313,"modelId":243092},{"sourceId":275529,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":235927,"modelId":257614}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":20266.423434,"end_time":"2025-02-13T00:05:22.229207","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-12T18:27:35.805773","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-05T10:03:58.227193Z","iopub.execute_input":"2025-03-05T10:03:58.227483Z","iopub.status.idle":"2025-03-05T10:03:58.954298Z","shell.execute_reply.started":"2025-03-05T10:03:58.227453Z","shell.execute_reply":"2025-03-05T10:03:58.953534Z"},"papermill":{"duration":0.746343,"end_time":"2025-02-12T18:27:39.157126","exception":false,"start_time":"2025-02-12T18:27:38.410783","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/regression_norm/keras/default/1/model_regression_norm.keras\n/kaggle/input/regression_norm_1100/keras/default/1/model_checkpoint (3).keras\n/kaggle/input/regression_norm_800/keras/default/1/model_checkpoint (2).keras\n/kaggle/input/ogw3-augmented/X_damage_augmented.npy\n/kaggle/input/ogw3-augmented/X_freq_augmented.npy\n/kaggle/input/ogw3-augmented/X_signals_augmented.npy\n/kaggle/input/regression_norm_500/keras/default/1/model_regression_norm_500.keras\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 1.5) loading augmented data","metadata":{"papermill":{"duration":0.005834,"end_time":"2025-02-12T18:27:39.169623","exception":false,"start_time":"2025-02-12T18:27:39.163789","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%pwd\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:07.289017Z","iopub.execute_input":"2025-03-05T10:04:07.289414Z","iopub.status.idle":"2025-03-05T10:04:07.295690Z","shell.execute_reply.started":"2025-03-05T10:04:07.289381Z","shell.execute_reply":"2025-03-05T10:04:07.294848Z"},"papermill":{"duration":0.012914,"end_time":"2025-02-12T18:27:39.188389","exception":false,"start_time":"2025-02-12T18:27:39.175475","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:10.131249Z","iopub.execute_input":"2025-03-05T10:04:10.131528Z","iopub.status.idle":"2025-03-05T10:04:10.135057Z","shell.execute_reply.started":"2025-03-05T10:04:10.131505Z","shell.execute_reply":"2025-03-05T10:04:10.134272Z"},"papermill":{"duration":0.010811,"end_time":"2025-02-12T18:27:39.205144","exception":false,"start_time":"2025-02-12T18:27:39.194333","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"os.chdir(\"..\")\nos.chdir(\"input\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:10.419727Z","iopub.execute_input":"2025-03-05T10:04:10.419958Z","iopub.status.idle":"2025-03-05T10:04:10.423313Z","shell.execute_reply.started":"2025-03-05T10:04:10.419938Z","shell.execute_reply":"2025-03-05T10:04:10.422506Z"},"papermill":{"duration":0.010396,"end_time":"2025-02-12T18:27:39.221430","exception":false,"start_time":"2025-02-12T18:27:39.211034","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"X_signals_augmented = np.load('ogw3-augmented/X_signals_augmented.npy')\nX_damage_augmented = np.load('ogw3-augmented/X_damage_augmented.npy')\nX_freq_augmented = np.load('ogw3-augmented/X_freq_augmented.npy')\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:10.673155Z","iopub.execute_input":"2025-03-05T10:04:10.673489Z","iopub.status.idle":"2025-03-05T10:04:11.735121Z","shell.execute_reply.started":"2025-03-05T10:04:10.673461Z","shell.execute_reply":"2025-03-05T10:04:11.734455Z"},"papermill":{"duration":1.084447,"end_time":"2025-02-12T18:27:40.311490","exception":false,"start_time":"2025-02-12T18:27:39.227043","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(f\"X_signals shape:{X_signals_augmented.shape}\")\nprint(f\"X_signals shape:{X_damage_augmented.shape}\")\nprint(f\"X_signals shape:{X_freq_augmented.shape}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:11.735984Z","iopub.execute_input":"2025-03-05T10:04:11.736281Z","iopub.status.idle":"2025-03-05T10:04:11.740136Z","shell.execute_reply.started":"2025-03-05T10:04:11.736259Z","shell.execute_reply":"2025-03-05T10:04:11.739362Z"},"papermill":{"duration":0.012117,"end_time":"2025-02-12T18:27:40.329873","exception":false,"start_time":"2025-02-12T18:27:40.317756","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"X_signals shape:(2040, 4369, 1)\nX_signals shape:(2040, 14)\nX_signals shape:(2040, 12)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\n\ndef summarize_data(X, name):\n    print(f\"Summary for {name}:\")\n    print(\"Mean:\", np.mean(X, axis=0))\n    print(\"Variance:\", np.var(X, axis=0))\n    print(\"Min:\", np.min(X, axis=0))\n    print(\"Max:\", np.max(X, axis=0))\n    print(\"-\" * 50)\n\nsummarize_data(X_signals_augmented, \"X_signals_augmented\")\nsummarize_data(X_freq_augmented, \"X_freq_augmented\")\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:16.663869Z","iopub.execute_input":"2025-03-05T10:04:16.664240Z","iopub.status.idle":"2025-03-05T10:04:16.765695Z","shell.execute_reply.started":"2025-03-05T10:04:16.664210Z","shell.execute_reply":"2025-03-05T10:04:16.764607Z"},"papermill":{"duration":0.101855,"end_time":"2025-02-12T18:27:40.437474","exception":false,"start_time":"2025-02-12T18:27:40.335619","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Summary for X_signals_augmented:\nMean: [[-0.00808563]\n [-0.03676917]\n [ 0.00793156]\n ...\n [ 0.43494834]\n [ 0.47826858]\n [ 0.47794448]]\nVariance: [[0.04756828]\n [0.05728288]\n [0.05182533]\n ...\n [0.11266843]\n [0.11778735]\n [0.1192308 ]]\nMin: [[-1.]\n [-1.]\n [-1.]\n ...\n [-1.]\n [-1.]\n [-1.]]\nMax: [[1.]\n [1.]\n [1.]\n ...\n [1.]\n [1.]\n [1.]]\n--------------------------------------------------\nSummary for X_freq_augmented:\nMean: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\nVariance: [0.07638889 0.07638889 0.07638889 0.07638889 0.07638889 0.07638889\n 0.07638889 0.07638889 0.07638889 0.07638889 0.07638889 0.07638889]\nMin: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\nMax: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\ndamage_counts = pd.Series(X_damage_augmented.flatten()).value_counts()\nprint(\"Damage Condition Counts:\\n\", damage_counts)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:20.103103Z","iopub.execute_input":"2025-03-05T10:04:20.103384Z","iopub.status.idle":"2025-03-05T10:04:20.121617Z","shell.execute_reply.started":"2025-03-05T10:04:20.103363Z","shell.execute_reply":"2025-03-05T10:04:20.120705Z"},"papermill":{"duration":0.023077,"end_time":"2025-02-12T18:27:40.466679","exception":false,"start_time":"2025-02-12T18:27:40.443602","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Damage Condition Counts:\n 0.0    26520\n1.0     2040\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# 2. Execution and model Training\nThis is where the actual execution starts","metadata":{"papermill":{"duration":0.005679,"end_time":"2025-02-12T18:27:40.478164","exception":false,"start_time":"2025-02-12T18:27:40.472485","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport matplotlib.pyplot as plt\nimport os","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:24.040630Z","iopub.execute_input":"2025-03-05T10:04:24.040912Z","iopub.status.idle":"2025-03-05T10:04:24.044584Z","shell.execute_reply.started":"2025-03-05T10:04:24.040879Z","shell.execute_reply":"2025-03-05T10:04:24.043704Z"},"papermill":{"duration":0.010665,"end_time":"2025-02-12T18:27:40.494844","exception":false,"start_time":"2025-02-12T18:27:40.484179","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# ----------------------------------------------------------------------\n# Step 1: Convert one-hot encoded damage labels to scalar values.\n# ----------------------------------------------------------------------\n# Each sample in X_damage_augmented is a one-hot vector. We convert it to the\n# corresponding class index (i.e., 0 for undamaged, 1-13 for damage levels).\ny_augmented = np.argmax(X_damage_augmented, axis=1).astype(np.float32)\n# y_augmented now has shape (num_samples,)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:27.226222Z","iopub.execute_input":"2025-03-05T10:04:27.226500Z","iopub.status.idle":"2025-03-05T10:04:27.788132Z","shell.execute_reply.started":"2025-03-05T10:04:27.226479Z","shell.execute_reply":"2025-03-05T10:04:27.787108Z"},"papermill":{"duration":1.139117,"end_time":"2025-02-12T18:27:41.640191","exception":false,"start_time":"2025-02-12T18:27:40.501074","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"y_augmented.min()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:29.593712Z","iopub.execute_input":"2025-03-05T10:04:29.594190Z","iopub.status.idle":"2025-03-05T10:04:29.599695Z","shell.execute_reply.started":"2025-03-05T10:04:29.594159Z","shell.execute_reply":"2025-03-05T10:04:29.598859Z"},"papermill":{"duration":0.01347,"end_time":"2025-02-12T18:27:41.660191","exception":false,"start_time":"2025-02-12T18:27:41.646721","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# ----------------------------------------------------------------------\n# Step 2: Define the features.\n# ----------------------------------------------------------------------\n# For this regression task, we use the guided wave signals as the features.\n# (If you wish to include frequency information as additional features, you might\n# concatenate or process X_freq_augmented separately; here we assume only the signal is used.)\nX_augmented = X_signals_augmented  # shape: (num_samples, 4369, 1)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:31.758150Z","iopub.execute_input":"2025-03-05T10:04:31.758436Z","iopub.status.idle":"2025-03-05T10:04:31.762324Z","shell.execute_reply.started":"2025-03-05T10:04:31.758413Z","shell.execute_reply":"2025-03-05T10:04:31.761416Z"},"papermill":{"duration":0.010841,"end_time":"2025-02-12T18:27:41.677098","exception":false,"start_time":"2025-02-12T18:27:41.666257","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ----------------------------------------------------------------------\n# Step 3: Split the data into training and test sets.\n# ----------------------------------------------------------------------\n# Here we use 80% of the data for training and 20% for testing.\nX_train, X_test, y_train, y_test = train_test_split(\n    X_augmented, y_augmented, test_size=0.1, random_state=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:36.193944Z","iopub.execute_input":"2025-03-05T10:04:36.194253Z","iopub.status.idle":"2025-03-05T10:04:36.224764Z","shell.execute_reply.started":"2025-03-05T10:04:36.194228Z","shell.execute_reply":"2025-03-05T10:04:36.224109Z"},"papermill":{"duration":0.037847,"end_time":"2025-02-12T18:27:41.720870","exception":false,"start_time":"2025-02-12T18:27:41.683023","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ----------------------------------------------------------------------\n# Step 4: Verify the shapes of the datasets.\n# ----------------------------------------------------------------------\nprint(f\"Training data shape: {X_train.shape}\")  # Expected: (num_train_samples, 4369, 1)\nprint(f\"Training labels shape: {y_train.shape}\")  # Expected: (num_train_samples,)\nprint(f\"Test data shape: {X_test.shape}\")         # Expected: (num_test_samples, 4369, 1)\nprint(f\"Test labels shape: {y_test.shape}\")         # Expected: (num_test_samples,)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:40.940208Z","iopub.execute_input":"2025-03-05T10:04:40.940505Z","iopub.status.idle":"2025-03-05T10:04:40.945784Z","shell.execute_reply.started":"2025-03-05T10:04:40.940481Z","shell.execute_reply":"2025-03-05T10:04:40.944977Z"},"papermill":{"duration":0.015982,"end_time":"2025-02-12T18:27:41.746389","exception":false,"start_time":"2025-02-12T18:27:41.730407","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Training data shape: (1836, 4369, 1)\nTraining labels shape: (1836,)\nTest data shape: (204, 4369, 1)\nTest labels shape: (204,)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def print_label_distribution(y, set_name):\n    \"\"\"Print the distribution of labels in a dataset.\"\"\"\n    print(f\"\\n{set_name} label distribution:\")\n    print(f\"- Baseline samples (0): {np.sum(y == 0)}\")\n    for damage_size in range(1, 14):\n        print(f\"- Damage size {damage_size}: {np.sum(y == damage_size)}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:41.357097Z","iopub.execute_input":"2025-03-05T10:04:41.357417Z","iopub.status.idle":"2025-03-05T10:04:41.361638Z","shell.execute_reply.started":"2025-03-05T10:04:41.357392Z","shell.execute_reply":"2025-03-05T10:04:41.360847Z"},"papermill":{"duration":0.016486,"end_time":"2025-02-12T18:27:41.770570","exception":false,"start_time":"2025-02-12T18:27:41.754084","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Print label distribution for training and test sets\nprint_label_distribution(y_train, \"Training set\")\nprint_label_distribution(y_test, \"Test set\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:43.917056Z","iopub.execute_input":"2025-03-05T10:04:43.917397Z","iopub.status.idle":"2025-03-05T10:04:43.926772Z","shell.execute_reply.started":"2025-03-05T10:04:43.917366Z","shell.execute_reply":"2025-03-05T10:04:43.924945Z"},"papermill":{"duration":0.016456,"end_time":"2025-02-12T18:27:41.794623","exception":false,"start_time":"2025-02-12T18:27:41.778167","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\nTraining set label distribution:\n- Baseline samples (0): 433\n- Damage size 1: 107\n- Damage size 2: 107\n- Damage size 3: 105\n- Damage size 4: 106\n- Damage size 5: 105\n- Damage size 6: 107\n- Damage size 7: 115\n- Damage size 8: 109\n- Damage size 9: 107\n- Damage size 10: 111\n- Damage size 11: 109\n- Damage size 12: 111\n- Damage size 13: 104\n\nTest set label distribution:\n- Baseline samples (0): 47\n- Damage size 1: 13\n- Damage size 2: 13\n- Damage size 3: 15\n- Damage size 4: 14\n- Damage size 5: 15\n- Damage size 6: 13\n- Damage size 7: 5\n- Damage size 8: 11\n- Damage size 9: 13\n- Damage size 10: 9\n- Damage size 11: 11\n- Damage size 12: 9\n- Damage size 13: 16\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Convert input data to float32\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:44.198413Z","iopub.execute_input":"2025-03-05T10:04:44.198662Z","iopub.status.idle":"2025-03-05T10:04:44.218676Z","shell.execute_reply.started":"2025-03-05T10:04:44.198632Z","shell.execute_reply":"2025-03-05T10:04:44.217943Z"},"papermill":{"duration":0.027121,"end_time":"2025-02-12T18:27:41.827880","exception":false,"start_time":"2025-02-12T18:27:41.800759","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"y_train = y_train.astype('int32')\ny_test = y_test.astype('int32')","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:44.593839Z","iopub.execute_input":"2025-03-05T10:04:44.594174Z","iopub.status.idle":"2025-03-05T10:04:44.597814Z","shell.execute_reply.started":"2025-03-05T10:04:44.594145Z","shell.execute_reply":"2025-03-05T10:04:44.596937Z"},"papermill":{"duration":0.011285,"end_time":"2025-02-12T18:27:41.845611","exception":false,"start_time":"2025-02-12T18:27:41.834326","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"print(\"Min values after scaling:\", np.min(X_train, axis=(1,2)))\nprint(\"Max values after scaling:\", np.max(X_train, axis=(1,2)))","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:47.328081Z","iopub.execute_input":"2025-03-05T10:04:47.328401Z","iopub.status.idle":"2025-03-05T10:04:47.349055Z","shell.execute_reply.started":"2025-03-05T10:04:47.328378Z","shell.execute_reply":"2025-03-05T10:04:47.348353Z"},"papermill":{"duration":0.027529,"end_time":"2025-02-12T18:27:41.879436","exception":false,"start_time":"2025-02-12T18:27:41.851907","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Min values after scaling: [-1.040155  -0.9812768 -1.        ... -1.        -0.9722817 -0.9399686]\nMax values after scaling: [1.0318567  0.94322634 1.         ... 1.         0.9312466  1.0010613 ]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"print(\"X_train dtype:\", X_train.dtype)  # Should print float32\nprint(\"y_train dtype:\", y_train.dtype)  # Should print float32","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:49.904220Z","iopub.execute_input":"2025-03-05T10:04:49.904527Z","iopub.status.idle":"2025-03-05T10:04:49.909454Z","shell.execute_reply.started":"2025-03-05T10:04:49.904498Z","shell.execute_reply":"2025-03-05T10:04:49.908740Z"},"papermill":{"duration":0.013338,"end_time":"2025-02-12T18:27:41.905268","exception":false,"start_time":"2025-02-12T18:27:41.891930","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"X_train dtype: float32\ny_train dtype: int32\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# 3. Model Architecture","metadata":{"papermill":{"duration":0.011179,"end_time":"2025-02-12T18:27:41.925914","exception":false,"start_time":"2025-02-12T18:27:41.914735","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:04:53.456669Z","iopub.execute_input":"2025-03-05T10:04:53.456988Z","iopub.status.idle":"2025-03-05T10:05:07.011756Z","shell.execute_reply.started":"2025-03-05T10:04:53.456960Z","shell.execute_reply":"2025-03-05T10:05:07.011108Z"},"papermill":{"duration":11.353666,"end_time":"2025-02-12T18:27:53.286918","exception":false,"start_time":"2025-02-12T18:27:41.933252","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"tf.keras.backend.set_floatx('float32')","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:05:12.185429Z","iopub.execute_input":"2025-03-05T10:05:12.185967Z","iopub.status.idle":"2025-03-05T10:05:12.190247Z","shell.execute_reply.started":"2025-03-05T10:05:12.185938Z","shell.execute_reply":"2025-03-05T10:05:12.189088Z"},"papermill":{"duration":0.011636,"end_time":"2025-02-12T18:27:53.304996","exception":false,"start_time":"2025-02-12T18:27:53.293360","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Multi-GPU setup\nstrategy = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:05:17.555424Z","iopub.execute_input":"2025-03-05T10:05:17.555707Z","iopub.status.idle":"2025-03-05T10:05:18.681127Z","shell.execute_reply.started":"2025-03-05T10:05:17.555686Z","shell.execute_reply":"2025-03-05T10:05:18.680135Z"},"papermill":{"duration":0.960545,"end_time":"2025-02-12T18:27:54.271600","exception":false,"start_time":"2025-02-12T18:27:53.311055","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:05:20.711989Z","iopub.execute_input":"2025-03-05T10:05:20.712326Z","iopub.status.idle":"2025-03-05T10:05:20.717278Z","shell.execute_reply.started":"2025-03-05T10:05:20.712298Z","shell.execute_reply":"2025-03-05T10:05:20.716472Z"},"papermill":{"duration":0.012715,"end_time":"2025-02-12T18:27:54.290868","exception":false,"start_time":"2025-02-12T18:27:54.278153","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input'"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Assume X_train has the shape (num_samples, 4369, 1)\nnum_samples, original_length, channels = X_train.shape\n\n# Calculate padding length so that the length becomes divisible by 5.\npad_len = 1\n\n# Pad along the sequence axis (axis=1) with -np.inf so that the max operation is not affected.\nX_train_padded = np.pad(\n    X_train,\n    pad_width=((0, 0), (0, pad_len), (0, 0)),\n    mode='constant',\n    constant_values=-np.inf\n)\n\n# Now X_train_padded has the shape (num_samples, 4370, 1).\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:05:25.127153Z","iopub.execute_input":"2025-03-05T10:05:25.127439Z","iopub.status.idle":"2025-03-05T10:05:25.141909Z","shell.execute_reply.started":"2025-03-05T10:05:25.127416Z","shell.execute_reply":"2025-03-05T10:05:25.140887Z"},"papermill":{"duration":0.021746,"end_time":"2025-02-12T18:27:54.318926","exception":false,"start_time":"2025-02-12T18:27:54.297180","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"X_train_padded.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:05:29.772245Z","iopub.execute_input":"2025-03-05T10:05:29.772568Z","iopub.status.idle":"2025-03-05T10:05:29.777775Z","shell.execute_reply.started":"2025-03-05T10:05:29.772544Z","shell.execute_reply":"2025-03-05T10:05:29.776860Z"},"papermill":{"duration":0.011871,"end_time":"2025-02-12T18:27:54.337038","exception":false,"start_time":"2025-02-12T18:27:54.325167","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(1836, 4370, 1)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"\n# Reshape to group every 5 consecutive elements:\n# New shape will be (num_samples, 874, 5, 1)\ngrouped_length = X_train_padded.shape[1] // 5  # Should be 874\nX_train_grouped = X_train_padded.reshape(num_samples, grouped_length, 5, channels)\n\n# Take the max over the 5 elements for each group (axis=2)\n# Resulting shape is (num_samples, 874, 1)\nX_train_max = np.max(X_train_grouped, axis=2)\n\n# Optionally, if your model expects inputs of shape (num_samples, 874),\n# reshape the array from (num_samples, 874, 1) to (num_samples, 874)\nX_train_final = X_train_max.reshape(num_samples, grouped_length)\n\n# Check the resulting shape\nprint(\"Shape after max-pooling and reshaping:\", X_train_final.shape)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:05:32.391275Z","iopub.execute_input":"2025-03-05T10:05:32.391586Z","iopub.status.idle":"2025-03-05T10:05:32.585352Z","shell.execute_reply.started":"2025-03-05T10:05:32.391563Z","shell.execute_reply":"2025-03-05T10:05:32.584652Z"},"papermill":{"duration":0.200656,"end_time":"2025-02-12T18:27:54.544210","exception":false,"start_time":"2025-02-12T18:27:54.343554","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Shape after max-pooling and reshaping: (1836, 874)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Assume X_train has the shape (num_samples, 4369, 1)\nnum_samples, original_length, channels = X_test.shape\n\n# Calculate padding length so that the length becomes divisible by 5.\npad_len = 1\n\n# Pad along the sequence axis (axis=1) with -np.inf so that the max operation is not affected.\nX_test_padded = np.pad(\n    X_test,\n    pad_width=((0, 0), (0, pad_len), (0, 0)),\n    mode='constant',\n    constant_values=-np.inf\n)\n\n# Now X_train_padded has the shape (num_samples, 4370, 1).\n\n# Reshape to group every 5 consecutive elements:\n# New shape will be (num_samples, 874, 5, 1)\ngrouped_length = X_test_padded.shape[1] // 5  # Should be 874\nX_test_grouped = X_test_padded.reshape(num_samples, grouped_length, 5, channels)\n\n# Take the max over the 5 elements for each group (axis=2)\n# Resulting shape is (num_samples, 874, 1)\nX_test_max = np.max(X_test_grouped, axis=2)\n\n# Optionally, if your model expects inputs of shape (num_samples, 874),\n# reshape the array from (num_samples, 874, 1) to (num_samples, 874)\nX_test_final = X_test_max.reshape(num_samples, grouped_length)\n\n# Check the resulting shape\nprint(\"Shape after max-pooling and reshaping:\", X_test_final.shape)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:05:37.427615Z","iopub.execute_input":"2025-03-05T10:05:37.427905Z","iopub.status.idle":"2025-03-05T10:05:37.458801Z","shell.execute_reply.started":"2025-03-05T10:05:37.427872Z","shell.execute_reply":"2025-03-05T10:05:37.458172Z"},"papermill":{"duration":0.036702,"end_time":"2025-02-12T18:27:54.587394","exception":false,"start_time":"2025-02-12T18:27:54.550692","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Shape after max-pooling and reshaping: (204, 874)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import numpy as np\n\n# Compute the minimum and maximum values from the training targets.\ny_min = np.min(y_train)\ny_max = np.max(y_train)\n\n# Normalize the training and test targets.\ny_train_norm = (y_train - y_min) / (y_max - y_min)\ny_test_norm = (y_test - y_min) / (y_max - y_min)\n\n\nprint(\"Before Normalizing training targets (first 5):\", y_train[:5])\nprint(\"Before Normalizing test targets (first 5):\", y_test[:5])\n\nprint(\"Normalized training targets (first 5):\", y_train_norm[:5])\nprint(\"Normalized test targets (first 5):\", y_test_norm[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T10:05:52.669199Z","iopub.execute_input":"2025-03-05T10:05:52.669511Z","iopub.status.idle":"2025-03-05T10:05:52.677479Z","shell.execute_reply.started":"2025-03-05T10:05:52.669486Z","shell.execute_reply":"2025-03-05T10:05:52.676637Z"}},"outputs":[{"name":"stdout","text":"Before Normalizing training targets (first 5): [ 5  3 13  1 10]\nBefore Normalizing test targets (first 5): [7 0 6 1 8]\nNormalized training targets (first 5): [0.38461538 0.23076923 1.         0.07692308 0.76923077]\nNormalized test targets (first 5): [0.53846154 0.         0.46153846 0.07692308 0.61538462]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the checkpoint callback to save every epoch\ncheckpoint_callback = ModelCheckpoint(\n    filepath='model_checkpoint.keras',  # Save file with epoch number and .keras extension\n    save_weights_only=False,  # Save the full model\n    save_freq='epoch',  # Save at the end of each epoch\n    verbose=1  # To print a message when the model is saved\n)\n\n# Modify the callbacks list to include the checkpoint callback \ncallbacks = [\n    keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True),\n    checkpoint_callback\n]\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:06:01.613350Z","iopub.execute_input":"2025-03-05T10:06:01.613623Z","iopub.status.idle":"2025-03-05T10:06:01.620116Z","shell.execute_reply.started":"2025-03-05T10:06:01.613600Z","shell.execute_reply":"2025-03-05T10:06:01.619245Z"},"papermill":{"duration":0.01342,"end_time":"2025-02-12T18:27:54.607476","exception":false,"start_time":"2025-02-12T18:27:54.594056","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:06:03.309270Z","iopub.execute_input":"2025-03-05T10:06:03.309554Z","iopub.status.idle":"2025-03-05T10:06:03.314839Z","shell.execute_reply.started":"2025-03-05T10:06:03.309532Z","shell.execute_reply":"2025-03-05T10:06:03.314007Z"},"papermill":{"duration":0.012325,"end_time":"2025-02-12T18:27:54.626110","exception":false,"start_time":"2025-02-12T18:27:54.613785","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input'"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"keras.config.enable_unsafe_deserialization()\n# Load the model within the strategy scope\nwith strategy.scope():\n    model_loaded = load_model('regression_norm_1100/keras/default/1/model_checkpoint (3).keras')","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:06:21.716920Z","iopub.execute_input":"2025-03-05T10:06:21.717301Z","iopub.status.idle":"2025-03-05T10:06:24.632906Z","shell.execute_reply.started":"2025-03-05T10:06:21.717271Z","shell.execute_reply":"2025-03-05T10:06:24.632173Z"},"papermill":{"duration":2.601845,"end_time":"2025-02-12T18:27:57.234259","exception":false,"start_time":"2025-02-12T18:27:54.632414","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"os.chdir(\"..\")\nos.chdir(\"working\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:06:30.946261Z","iopub.execute_input":"2025-03-05T10:06:30.946593Z","iopub.status.idle":"2025-03-05T10:06:30.950557Z","shell.execute_reply.started":"2025-03-05T10:06:30.946564Z","shell.execute_reply":"2025-03-05T10:06:30.949582Z"},"papermill":{"duration":0.011675,"end_time":"2025-02-12T18:27:57.252737","exception":false,"start_time":"2025-02-12T18:27:57.241062","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:06:32.933427Z","iopub.execute_input":"2025-03-05T10:06:32.933710Z","iopub.status.idle":"2025-03-05T10:06:32.938946Z","shell.execute_reply.started":"2025-03-05T10:06:32.933687Z","shell.execute_reply":"2025-03-05T10:06:32.938009Z"},"papermill":{"duration":0.01242,"end_time":"2025-02-12T18:27:57.271502","exception":false,"start_time":"2025-02-12T18:27:57.259082","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"\n\n\n# Continue training for an additional 300 epochs\nhistory_additional = model_loaded.fit(\n    X_train_final,\n    y_train_norm,\n    validation_data=(X_test_final, y_test_norm),\n    epochs=3,  # Train for 300 more epochs\n    batch_size=32,\n    callbacks=callbacks,\n    verbose=1\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T10:06:36.189433Z","iopub.execute_input":"2025-03-05T10:06:36.189719Z","iopub.status.idle":"2025-03-05T10:09:51.723949Z","shell.execute_reply.started":"2025-03-05T10:06:36.189696Z","shell.execute_reply":"2025-03-05T10:09:51.723237Z"},"papermill":{"duration":20241.093053,"end_time":"2025-02-13T00:05:18.370907","exception":false,"start_time":"2025-02-12T18:27:57.277854","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913ms/step - loss: 0.0134 - mae: 0.0876\nEpoch 1: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 992ms/step - loss: 0.0134 - mae: 0.0876 - val_loss: 0.0228 - val_mae: 0.1062\nEpoch 2/3\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978ms/step - loss: 0.0142 - mae: 0.0911\nEpoch 2: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0142 - mae: 0.0911 - val_loss: 0.0210 - val_mae: 0.0981\nEpoch 3/3\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967ms/step - loss: 0.0128 - mae: 0.0848\nEpoch 3: saving model to model_checkpoint.keras\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0128 - mae: 0.0848 - val_loss: 0.0199 - val_mae: 0.0964\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}